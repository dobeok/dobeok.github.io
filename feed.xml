<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://dobeok.github.io//jekyll-theme-yat/feed.xml" rel="self" type="application/atom+xml" /><link href="https://dobeok.github.io//jekyll-theme-yat/" rel="alternate" type="text/html" /><updated>2023-03-12T10:49:39+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/feed.xml</id><title type="html">My data science projects</title><subtitle></subtitle><author><name>Vo Duy Do</name></author><entry><title type="html">Analyzing Singapore’s HDB flats resale price</title><link href="https://dobeok.github.io//jekyll-theme-yat/2023/03/08/predict-hdb-resale.html" rel="alternate" type="text/html" title="Analyzing Singapore’s HDB flats resale price" /><published>2023-03-08T05:00:00+00:00</published><updated>2023-03-08T05:00:00+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2023/03/08/predict-hdb-resale</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2023/03/08/predict-hdb-resale.html"><![CDATA[<p>In this series I will be modeling Singapore’s HDB flats resale price. The first part is about building a model, following a standard ML problem process (EDA, Feature Engineering, Split train/test data, Fit model, Evaluation). The second part (coming soon™) will be about mlops. I will use <code class="language-plaintext highlighter-rouge">mlflow</code> to track and manage experiments &amp; models.</p>

<p>Part 1 (This post)</p>
<ul>
  <li>Train different models to predict resale price for Singapore’s HDB</li>
</ul>

<p>Part 2 (Coming soon™)</p>
<ul>
  <li>Run &amp; Log experiments and models using <code class="language-plaintext highlighter-rouge">mlflow</code></li>
  <li>Save models to model registry</li>
  <li>Load and serve the best model</li>
</ul>

<details><summary>What are HDB flats?</summary>
    <ul>
    <li> HDB (Housing and Development Board) buildings are public housing blocks in Singapore. They were built and managed by the Housing and Development Board (HDB), a statutory board under the Ministry of National Development. 
    <li>
    HDB flats range from studio apartments to executive apartments, and are available for purchase or rent. Today 80% of Singapore's population live in HDB flats.
    </li>
    </li>
    <li>
    HDB flats are typically located in housing estates, which are self-contained communities with amenities such as schools, markets, and parks. The HDB also manages and maintains the estates, ensuring that they remain safe, clean and well-maintained.
    </li>
    </ul>

</details>

<h2 id="0-import-and-read-data">0. Import and read data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="kn">import</span> <span class="n">geopandas</span> <span class="k">as</span> <span class="n">gpd</span>
<span class="kn">from</span> <span class="n">shapely.geometry</span> <span class="kn">import</span> <span class="n">Point</span>
<span class="kn">import</span> <span class="n">folium</span>

<span class="kn">from</span> <span class="n">math</span> <span class="kn">import</span> <span class="n">radians</span><span class="p">,</span> <span class="n">cos</span><span class="p">,</span> <span class="n">sin</span><span class="p">,</span> <span class="n">asin</span><span class="p">,</span> <span class="n">sqrt</span>

<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span><span class="p">,</span> <span class="n">GradientBoostingRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVR</span>

<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="s">'seaborn-v0_8-white'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s">'./data/intermediate/intermediate-data.csv'</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s">'Unnamed: 0'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'town'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'town'</span><span class="p">].</span><span class="nf">replace</span><span class="p">({</span><span class="s">'KALLANG/WHAMPOA'</span><span class="p">:</span> <span class="s">'KALLANG'</span><span class="p">})</span>

<span class="n">df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(133473, 16)
</code></pre></div></div>

<h2 id="1-exploratory-data-analysis">1. Exploratory Data Analysis</h2>

<p>Preview dataset</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">().</span><span class="n">T</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>month</th>
      <td>2017-01</td>
      <td>2017-01</td>
      <td>2017-01</td>
      <td>2017-01</td>
      <td>2017-01</td>
    </tr>
    <tr>
      <th>town</th>
      <td>ANG MO KIO</td>
      <td>ANG MO KIO</td>
      <td>ANG MO KIO</td>
      <td>ANG MO KIO</td>
      <td>ANG MO KIO</td>
    </tr>
    <tr>
      <th>flat_type</th>
      <td>2 ROOM</td>
      <td>3 ROOM</td>
      <td>3 ROOM</td>
      <td>3 ROOM</td>
      <td>3 ROOM</td>
    </tr>
    <tr>
      <th>block</th>
      <td>406</td>
      <td>108</td>
      <td>602</td>
      <td>465</td>
      <td>601</td>
    </tr>
    <tr>
      <th>street_name_x</th>
      <td>ANG MO KIO AVE 10</td>
      <td>ANG MO KIO AVE 4</td>
      <td>ANG MO KIO AVE 5</td>
      <td>ANG MO KIO AVE 10</td>
      <td>ANG MO KIO AVE 5</td>
    </tr>
    <tr>
      <th>storey_range</th>
      <td>10 TO 12</td>
      <td>01 TO 03</td>
      <td>01 TO 03</td>
      <td>04 TO 06</td>
      <td>01 TO 03</td>
    </tr>
    <tr>
      <th>floor_area_sqm</th>
      <td>44.0</td>
      <td>67.0</td>
      <td>67.0</td>
      <td>68.0</td>
      <td>67.0</td>
    </tr>
    <tr>
      <th>flat_model</th>
      <td>Improved</td>
      <td>New Generation</td>
      <td>New Generation</td>
      <td>New Generation</td>
      <td>New Generation</td>
    </tr>
    <tr>
      <th>lease_commence_date</th>
      <td>1979</td>
      <td>1978</td>
      <td>1980</td>
      <td>1980</td>
      <td>1980</td>
    </tr>
    <tr>
      <th>remaining_lease</th>
      <td>61 years 04 months</td>
      <td>60 years 07 months</td>
      <td>62 years 05 months</td>
      <td>62 years 01 month</td>
      <td>62 years 05 months</td>
    </tr>
    <tr>
      <th>resale_price</th>
      <td>232000.0</td>
      <td>250000.0</td>
      <td>262000.0</td>
      <td>265000.0</td>
      <td>265000.0</td>
    </tr>
    <tr>
      <th>postal</th>
      <td>560406.0</td>
      <td>560108.0</td>
      <td>560602.0</td>
      <td>560465.0</td>
      <td>560601.0</td>
    </tr>
    <tr>
      <th>latitude</th>
      <td>1.362005</td>
      <td>1.370966</td>
      <td>1.380709</td>
      <td>1.366201</td>
      <td>1.381041</td>
    </tr>
    <tr>
      <th>longitude</th>
      <td>103.85388</td>
      <td>103.838202</td>
      <td>103.835368</td>
      <td>103.857201</td>
      <td>103.835132</td>
    </tr>
    <tr>
      <th>building</th>
      <td>HDB-ANG MO KIO</td>
      <td>KEBUN BARU HEIGHTS</td>
      <td>YIO CHU KANG GREEN</td>
      <td>TECK GHEE HORIZON</td>
      <td>YIO CHU KANG GREEN</td>
    </tr>
    <tr>
      <th>address</th>
      <td>406 ANG MO KIO AVENUE 10 HDB-ANG MO KIO SINGAP...</td>
      <td>108 ANG MO KIO AVENUE 4 KEBUN BARU HEIGHTS SIN...</td>
      <td>602 ANG MO KIO AVENUE 5 YIO CHU KANG GREEN SIN...</td>
      <td>465 ANG MO KIO AVENUE 10 TECK GHEE HORIZON SIN...</td>
      <td>601 ANG MO KIO AVENUE 5 YIO CHU KANG GREEN SIN...</td>
    </tr>
  </tbody>
</table>
</div>

<p>Checking for null/NaN data. In this case the percentage of rows having missing data are low, so it’s safe to drop them</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">mean</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>month                  0.000000
town                   0.000000
flat_type              0.000000
block                  0.000000
street_name_x          0.000000
storey_range           0.000000
floor_area_sqm         0.000000
flat_model             0.000000
lease_commence_date    0.000000
remaining_lease        0.000000
resale_price           0.000000
postal                 0.018513
latitude               0.018513
longitude              0.018513
building               0.018513
address                0.018513
dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'latitude'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">()].</span><span class="n">index</span><span class="p">)</span>
</code></pre></div></div>

<p>Now let’s look at the overall distribution of resale price, henceforth also refered to as the target variable.</p>

<p>The distribution is right-skewed with few but very high values. The median value (SGD 440k) is lower than average (SGD 470k)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">height_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>

<span class="n">df</span><span class="p">[</span><span class="s">'resale_price'</span><span class="p">].</span><span class="nf">hist</span><span class="p">(</span>
    <span class="n">ec</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="n">_</span> <span class="o">*</span> <span class="mi">50_000</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">30</span><span class="p">)],</span>
    <span class="n">grid</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">axvline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'resale_price'</span><span class="p">].</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s">"avg = SGD </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'resale_price'</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span><span class="si">:</span><span class="p">,.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">axvline</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'resale_price'</span><span class="p">].</span><span class="nf">median</span><span class="p">(),</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s">"median = SGD </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'resale_price'</span><span class="p">].</span><span class="nf">median</span><span class="p">()</span><span class="si">:</span><span class="p">,.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xticks</span><span class="p">([</span><span class="n">_</span> <span class="o">*</span> <span class="mi">100_000</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">14</span><span class="p">)],</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="n">_</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">14</span><span class="p">)])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s">'Unit: thousands SGD'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'resale_price'</span><span class="p">],</span> <span class="n">orient</span><span class="o">=</span><span class="s">"h"</span><span class="p">,</span> <span class="n">showfliers</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">left</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="s">'HDB Resale Price Distribution'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/01-predict-hdb-resale_files/01-predict-hdb-resale_12_0.png" alt="png" /></p>

<h4 id="numerical-variables">Numerical variables</h4>

<p>Correlations between each numeric variables and the target value give us a good sense of how much predicting power they have.</p>

<p>Unsurprisingly, bigger and newer flats are positively correlated with resale price</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s">'resale_price'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">corrwith</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'resale_price'</span><span class="p">],</span> <span class="n">numeric_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'barh'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'Correlation with resale price'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/01-predict-hdb-resale_files/01-predict-hdb-resale_15_0.png" alt="png" /></p>

<p>We can also study how much feature variables correlate with each other. If we solely care about having a good prediction, then it’s ok to have correlated features! However, if we want to study the impact of each variable, it’s helpful to remove redundant dimensions.</p>

<p>In the heatmap below, <code class="language-plaintext highlighter-rouge">latitude</code> and <code class="language-plaintext highlighter-rouge">postal</code> are highly correlated, we will drop at least 1 of them before fitting the models. However for now we will keep them to create a more useful feature.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">corr</span><span class="p">(</span><span class="n">numeric_only</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># remove the top triangle of the matrix to simplify the heatmap
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">triu_indices_from</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span>
    <span class="n">corr_matrix</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
    <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">(</span><span class="s">"vlag_r"</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/01-predict-hdb-resale_files/01-predict-hdb-resale_17_1.png" alt="png" /></p>

<h4 id="categorical-variables">Categorical variables</h4>

<p><code class="language-plaintext highlighter-rouge">block</code>, <code class="language-plaintext highlighter-rouge">building</code>, <code class="language-plaintext highlighter-rouge">address</code> contains too many categories. This might cause overfitting or computational issues then we will not be using those variables.</p>

<p>Perhaps the most useful feature we can use here is <code class="language-plaintext highlighter-rouge">flat_type</code>. The possible values are: <code class="language-plaintext highlighter-rouge">2 ROOM</code> , <code class="language-plaintext highlighter-rouge">3 ROOM</code>, <code class="language-plaintext highlighter-rouge">4 ROOM</code>, <code class="language-plaintext highlighter-rouge">5 ROOM</code>, <code class="language-plaintext highlighter-rouge">Executive</code>, <code class="language-plaintext highlighter-rouge">Multi-generationl</code>. There are a few ways to deal with this data. For simplicity, I will convert them to number of rooms so we can have a nice numeric value.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">select_dtypes</span><span class="p">(</span><span class="s">'object'</span><span class="p">).</span><span class="nf">nunique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>month                68
town                 26
flat_type             6
block              2580
street_name_x       556
storey_range         17
flat_model           21
remaining_lease     653
building            612
address            8896
dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s">'resale_price'</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s">'flat_model'</span><span class="p">,</span>
    <span class="n">palette</span><span class="o">=</span><span class="s">"Reds"</span><span class="p">,</span>
    <span class="n">showfliers</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">).</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'`flat_model` has too many categories'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/01-predict-hdb-resale_files/01-predict-hdb-resale_20_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s">'resale_price'</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s">'flat_type'</span><span class="p">,</span>
    <span class="n">palette</span><span class="o">=</span><span class="s">"Reds"</span><span class="p">,</span>
    <span class="n">showfliers</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">).</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'`flat_type` has a few categories and has little overlap. Making this a good feature'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/01-predict-hdb-resale_files/01-predict-hdb-resale_21_1.png" alt="png" /></p>

<h2 id="2-feature-engineering">2. Feature engineering</h2>

<p>Intuitively, we know that location is one of the most important factor in determining house prices. We will need a way to add this information to our model. To visualize the impact of location, I’ve created a choropleth map.</p>

<p>It’s visible from the map that the further towns have lower price range.</p>

<details>
<summary>Show code</summary>

<script src="https://gist.github.com/dobeok/6a7a2251a949b3404baf72e546e4ee55.js"></script>
</details>

<div style="width:100%;">
    <div style="position:relative;width:100%;height:0;padding-bottom:60%;">
        <span style="color:#565656">Make this Notebook Trusted to load map: File -&gt; Trust Notebook</span>
            <iframe src="/assets/images/posts/01-predict-hdb-resale_files/town_map.html" style="position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen="">
            </iframe>
    </div>
</div>
<p><br /></p>

<p>To determine how central a location it, I will calculate the straight line distance to a center point. For Singapore, I’ve selected the point having coordinate value <code class="language-plaintext highlighter-rouge">CITY_CENTER = (1.28019, 103.85175)</code>. This point was picked by eyeballing on google map.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">haversine</span><span class="p">(</span><span class="n">lon1</span><span class="p">,</span> <span class="n">lat1</span><span class="p">,</span> <span class="n">lon2</span><span class="p">,</span> <span class="n">lat2</span><span class="p">):</span>
    <span class="s">"""
    Calculate the great circle distance in kilometers between two points 
    on the earth (specified in decimal degrees)
    """</span>
    <span class="c1"># convert decimal degrees to radians 
</span>    <span class="n">lon1</span><span class="p">,</span> <span class="n">lat1</span><span class="p">,</span> <span class="n">lon2</span><span class="p">,</span> <span class="n">lat2</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="n">radians</span><span class="p">,</span> <span class="p">[</span><span class="n">lon1</span><span class="p">,</span> <span class="n">lat1</span><span class="p">,</span> <span class="n">lon2</span><span class="p">,</span> <span class="n">lat2</span><span class="p">])</span>

    <span class="c1"># haversine formula 
</span>    <span class="n">dlon</span> <span class="o">=</span> <span class="n">lon2</span> <span class="o">-</span> <span class="n">lon1</span> 
    <span class="n">dlat</span> <span class="o">=</span> <span class="n">lat2</span> <span class="o">-</span> <span class="n">lat1</span> 
    <span class="n">a</span> <span class="o">=</span> <span class="nf">sin</span><span class="p">(</span><span class="n">dlat</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="nf">cos</span><span class="p">(</span><span class="n">lat1</span><span class="p">)</span> <span class="o">*</span> <span class="nf">cos</span><span class="p">(</span><span class="n">lat2</span><span class="p">)</span> <span class="o">*</span> <span class="nf">sin</span><span class="p">(</span><span class="n">dlon</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">c</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nf">asin</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">))</span> 
    
    <span class="c1"># constant used to convert to km
</span>    <span class="n">r</span> <span class="o">=</span> <span class="mi">6371</span>
    
    <span class="k">return</span> <span class="n">c</span> <span class="o">*</span> <span class="n">r</span>


<span class="n">df</span><span class="p">[</span><span class="s">'distance_from_center'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">haversine</span><span class="p">(</span>
        <span class="n">x</span><span class="p">[</span><span class="s">'longitude'</span><span class="p">],</span>
        <span class="n">x</span><span class="p">[</span><span class="s">'latitude'</span><span class="p">],</span>
        <span class="n">CITY_CENTER</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">CITY_CENTER</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="distance-to-the-nearest-mrt-station">Distance to the nearest MRT station</h3>

<p>Other than distance to city center, close priximity to amenities and public transportations could also make the flats more attractive and hence having higher price. I will now calculate distance from the nearest MRT station to each of the HDB block.</p>

<p>To make calculations faster, I’ve (1) estimated the nearest location using Pythagorean theorem, and then (2) use the haversine formula above to determine actual distance in kilometers. This will save some calculation time.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># hdb_ll -&gt; np.ndarray
</span>
<span class="c1"># latitude is the x-axis
# longitude is the y-axis
</span><span class="n">hdb_ll</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'longitude'</span><span class="p">,</span> <span class="s">'latitude'</span><span class="p">]].</span><span class="n">values</span>

<span class="c1"># find nearst mrt
</span><span class="n">x_delta</span> <span class="o">=</span> <span class="p">(</span><span class="n">mrt_map</span><span class="p">.</span><span class="n">geometry</span><span class="p">.</span><span class="n">x</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">hdb_ll</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">y_delta</span> <span class="o">=</span> <span class="p">(</span><span class="n">mrt_map</span><span class="p">.</span><span class="n">geometry</span><span class="p">.</span><span class="n">y</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">hdb_ll</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">delta</span> <span class="o">=</span> <span class="p">((</span><span class="n">x_delta</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">y_delta</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="p">.</span><span class="mi">5</span>

<span class="n">df</span><span class="p">[</span><span class="s">'nearest_mrt_id'</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'nearest_mrt_location'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'nearest_mrt_id'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">mrt_map</span><span class="p">.</span><span class="n">geometry</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">mrt_map</span><span class="p">.</span><span class="n">index</span><span class="p">).</span><span class="nf">to_dict</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s">'nearest_mrt_longitude'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'nearest_mrt_location'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">val</span><span class="p">:</span> <span class="n">val</span><span class="p">.</span><span class="n">x</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'nearest_mrt_latitude'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'nearest_mrt_location'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">val</span><span class="p">:</span> <span class="n">val</span><span class="p">.</span><span class="n">y</span><span class="p">)</span>

<span class="n">df</span><span class="p">[</span><span class="s">'distance_to_mrt'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span>
    <span class="nf">haversine</span><span class="p">(</span>
        <span class="n">x</span><span class="p">[</span><span class="s">'longitude'</span><span class="p">],</span>
        <span class="n">x</span><span class="p">[</span><span class="s">'latitude'</span><span class="p">],</span>
        <span class="n">x</span><span class="p">[</span><span class="s">'nearest_mrt_longitude'</span><span class="p">],</span>
        <span class="n">x</span><span class="p">[</span><span class="s">'nearest_mrt_latitude'</span><span class="p">]),</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'nearest_mrt_longitude'</span><span class="p">,</span> <span class="s">'nearest_mrt_latitude'</span><span class="p">,</span> <span class="s">'nearest_mrt_id'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="other-features">Other features</h3>

<p>Here’s the remaining features to process:</p>
<ul>
  <li>Convert remaining lease duration from year-month format to months</li>
  <li>Create a new feature called number of bedrooms from flat type (explained above)</li>
  <li>Averaged storey number since the original dataset list a range instead of exact floor number</li>
  <li>Drop values for rare types</li>
  <li>Drop highly correlated features</li>
  <li>Use boxlots to determine appropriate feature range. Optionally drop outliers.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert `remaining_lease_months` from years months to months
</span><span class="n">df</span><span class="p">[</span><span class="s">'remaining_lease'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">contains</span><span class="p">(</span><span class="s">'year'</span><span class="p">).</span><span class="nf">value_counts</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s">'remaining_lease_months'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'remaining_lease'</span><span class="p">].</span><span class="nb">str</span><span class="p">[:</span><span class="mi">2</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">*</span> <span class="mi">12</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s">'remaining_lease'</span><span class="p">].</span><span class="nb">str</span><span class="p">[</span><span class="o">-</span><span class="mi">9</span><span class="p">:</span><span class="o">-</span><span class="mi">7</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>


<span class="c1"># convert flat type to number of rooms
# https://www.hdb.gov.sg/residential/buying-a-flat/finding-a-flat/types-of-flats
</span><span class="n">df</span><span class="p">[</span><span class="s">'num_bedrooms'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'flat_type'</span><span class="p">].</span><span class="nf">map</span><span class="p">({</span>
    <span class="s">'1 ROOM'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="s">'2 ROOM'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s">'3 ROOM'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s">'4 ROOM'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s">'5 ROOM'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s">'EXECUTIVE'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s">'MULTI-GENERATION'</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
<span class="p">})</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'num_bedrooms'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">()].</span><span class="n">index</span><span class="p">)</span>

<span class="c1"># convert storey range to mean of range
</span><span class="n">df</span><span class="p">[</span><span class="s">'storey_range_feature'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'storey_range'</span><span class="p">].</span><span class="nb">str</span><span class="p">[:</span><span class="mi">2</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s">'storey_range'</span><span class="p">].</span><span class="nb">str</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>

<span class="c1"># drop highly correlated features
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'lease_commence_date'</span><span class="p">,</span> <span class="s">'postal'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>


<span class="n">numerical_feature_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">'num_bedrooms'</span><span class="p">,</span>
    <span class="s">'floor_area_sqm'</span><span class="p">,</span>
    <span class="s">'storey_range_feature'</span><span class="p">,</span>
    <span class="s">'remaining_lease_months'</span><span class="p">,</span>
    <span class="s">'distance_to_mrt'</span><span class="p">,</span>
    <span class="s">'distance_from_center'</span><span class="p">,</span>
    <span class="s">'floor_area_sqm'</span><span class="p">,</span>
    <span class="p">]</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">numerical_feature_cols</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">numerical_feature_cols</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col_name</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">col_name</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="s">'_'</span><span class="p">,</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s">'left'</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/01-predict-hdb-resale_files/01-predict-hdb-resale_32_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># remove outliers
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'floor_area_sqm'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">df</span><span class="p">[</span><span class="s">'floor_area_sqm'</span><span class="p">].</span><span class="nf">quantile</span><span class="p">(.</span><span class="mi">95</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">dropna</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>


<span class="c1"># correlation between numeric variables and target
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s">'resale_price'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">corrwith</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'resale_price'</span><span class="p">],</span> <span class="n">numeric_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'barh'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'Correlation with resale price'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/01-predict-hdb-resale_files/01-predict-hdb-resale_34_0.png" alt="png" /></p>

<h2 id="3-split-train-test-data">3. Split train-test data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">numerical_feature_cols</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'resale_price'</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="4-fit-models">4. Fit models</h2>

<h4 id="41-linear-regresssion-baseline">4.1 Linear Regresssion (baseline)</h4>

<p>I will first fit a simple estimator, which will be used as baseline.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr_model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'fitting </span><span class="si">{</span><span class="n">lr_model</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">lr_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">lr_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">rmse</span><span class="o">=</span><span class="si">:</span><span class="p">,.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fitting LinearRegression
rmse=78,280
</code></pre></div></div>

<h4 id="42-decision-trees-random-forest-gradientboosting-svr">4.2 Decision Trees, Random Forest, GradientBoosting, SVR</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rf_model</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'fitting </span><span class="si">{</span><span class="n">rf_model</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">rf_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">rf_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">rmse</span><span class="o">=</span><span class="si">:</span><span class="p">,.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fitting RandomForestRegressor
rmse=33,531
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gb_model</span> <span class="o">=</span> <span class="nc">GradientBoostingRegressor</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'fitting </span><span class="si">{</span><span class="n">gb_model</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">gb_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">gb_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">rmse</span><span class="o">=</span><span class="si">:</span><span class="p">,.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fitting GradientBoostingRegressor
rmse=60,247
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">svr_model</span> <span class="o">=</span> <span class="nc">LinearSVR</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'fitting </span><span class="si">{</span><span class="n">svr_model</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">svr_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">svr_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">rmse</span><span class="o">=</span><span class="si">:</span><span class="p">,.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fitting LinearSVR
rmse=81,687
</code></pre></div></div>

<h4 id="making-predictions-on-sample-data">Making predictions on sample data</h4>

<p>To get more specific sense of each model’s performace, we can select random test data and check for each model’s predictions</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># select random indices
</span><span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">sample_predictions</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="p">[</span><span class="n">lr_model</span><span class="p">,</span> <span class="n">rf_model</span><span class="p">,</span> <span class="n">gb_model</span><span class="p">,</span> <span class="n">svr_model</span><span class="p">]:</span>
    <span class="n">sample_predictions</span><span class="p">[</span><span class="n">model</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

<span class="n">sample_predictions</span><span class="p">[</span><span class="s">'Ground Truth'</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">sample_predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">sample_predictions</span><span class="p">)</span>

<span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">sample_predictions</span><span class="p">).</span><span class="nf">plot</span><span class="p">(</span>
    <span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span>
    <span class="n">rot</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s">'flat id'</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s">'SGD'</span><span class="p">)</span> \
    <span class="p">.</span><span class="nf">legend</span><span class="p">(</span>
        <span class="n">loc</span><span class="o">=</span><span class="s">'center left'</span><span class="p">,</span>
        <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
</code></pre></div></div>
<p><img src="/assets/images/posts/01-predict-hdb-resale_files/01-predict-hdb-resale_47_1.png" alt="png" /></p>

<p>Out of the few models above, RandomForests perform the best. With a RMSE of 33.4k. In real terms, for a property that cost on average close to 500k, being off by 33k is decent.</p>

<p>However, there are a lot more that we can do here:
    1. Selecting different models
    2. Optimizing hyperparameters, for example, using GridSearch or Hyperopt.</p>

<p>Without mlflow, we will have to manually keep track of model parameteres, data sources, metrics, etc (such as in a google sheet). This is prone to errors and hard to keep track.</p>

<h2 id="5-summary-so-far">5. Summary (so far)</h2>

<p>I created basic HDB resale price prediction models with two additional features for centrality and proximity to MRT stations, on top of existing features such as living area, town name, and flat type.</p>

<p>RandomForest outperforms single complex models due to its use of many relatively uncorrelated trees as a committee. Further improvement to predictions can be achieved by adding more relevant features, such as proximity to good schools, shopping malls, and other amenities.</p>

<p>House prices could also be predicted using a Time Series model like ARIMA, among other potential approaches.</p>]]></content><author><name>Vo Duy Do</name></author><category term="analysis" /><category term="visualization" /><summary type="html"><![CDATA[Explore & model Singapore's HDB flats resale price using different prediction models. Engineering new features such as centrality and proximity to MRT stations. Out of the box, RandomForest performs better than single complex models with minimal hyperparameters tuning]]></summary></entry><entry><title type="html">Predicting loan defaults</title><link href="https://dobeok.github.io//jekyll-theme-yat/2023/02/23/predict-loan.html" rel="alternate" type="text/html" title="Predicting loan defaults" /><published>2023-02-23T05:00:00+00:00</published><updated>2023-02-23T05:00:00+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2023/02/23/predict-loan</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2023/02/23/predict-loan.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<ul>
  <li>
    <p>The goal of this task is to fit a statistical model to historical credit data and then use the model to estimate the value of current loans.</p>
  </li>
  <li>
    <p>Since this is a binary classification problem where the target variable is either DEFAULT or PAID, I will use Logistics Regression.</p>
  </li>
  <li>
    <p>In addition to model building, I will illustrate how sklearn’s Pipeline is more convenient and simple to use than manually doing all transformation steps - especially for Cross Validation and Hyperparameters Tuning</p>
  </li>
</ul>

<p>Data descriptions</p>

<table>
  <thead>
    <tr>
      <th>Column</th>
      <th>account_no</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>account_no</td>
      <td>A unique account number per loan</td>
    </tr>
    <tr>
      <td>gender</td>
      <td>The gender of the account holder - either <code class="language-plaintext highlighter-rouge">"M"</code> or <code class="language-plaintext highlighter-rouge">"F"</code></td>
    </tr>
    <tr>
      <td>age</td>
      <td>The age of the account holder at the point of application</td>
    </tr>
    <tr>
      <td>income</td>
      <td>The monthly net income of the account holder at the point of application</td>
    </tr>
    <tr>
      <td>loan_amount</td>
      <td>The amount of money lent</td>
    </tr>
    <tr>
      <td>term</td>
      <td>The number of months that the loan is to be repaid over</td>
    </tr>
    <tr>
      <td>installment_amount</td>
      <td>The monthly installment amount</td>
    </tr>
    <tr>
      <td>interest_rate</td>
      <td>The interest rate on the loan</td>
    </tr>
    <tr>
      <td>credit_score_at_application</td>
      <td>The credit score at the point of application, this is a positive integer less than 1000. The higher the score the more creditworthy the applicant is believed to be</td>
    </tr>
    <tr>
      <td>outstanding_balance</td>
      <td>The remaining amount of the loan that still has to be repaid</td>
    </tr>
    <tr>
      <td>status</td>
      <td>This indicates what state the account is in. This field can take one of three values<br />- <code class="language-plaintext highlighter-rouge">"LIVE"</code> : The loan is still being repaid - the field <code class="language-plaintext highlighter-rouge">outstanding_balance</code>  will be greater than zero.<br />- <code class="language-plaintext highlighter-rouge">"PAID_UP"</code>: The loan has been completely repaid - the field <code class="language-plaintext highlighter-rouge">outstanding_balance</code> will be zero.<br />- <code class="language-plaintext highlighter-rouge">"DEFAULT"</code>: The loan was not fully repaid and no further payments can be expected - the field <code class="language-plaintext highlighter-rouge">outstanding_balance</code> will be greater than zero and the amount will not be recoverable.</td>
    </tr>
  </tbody>
</table>

<h2 id="0-imports-and-read-data">0. Imports and read data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="n">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s">'./data/loan_default.csv'</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>**index**</th>
      <th>**account_no**</th>
      <th>**gender**</th>
      <th>**age**</th>
      <th>**income**</th>
      <th>**loan_amount**</th>
      <th>**term**</th>
      <th>**installment_amount**</th>
      <th>**interest_rate**</th>
      <th>**credit_score_at_application**</th>
      <th>**outstanding_balance**</th>
      <th>**status**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>acc_00000316</td>
      <td>F</td>
      <td>18</td>
      <td>12143</td>
      <td>47000</td>
      <td>60</td>
      <td>1045</td>
      <td>0.12</td>
      <td>860</td>
      <td>0</td>
      <td>PAID_UP</td>
    </tr>
    <tr>
      <td>1</td>
      <td>acc_00000422</td>
      <td>F</td>
      <td>18</td>
      <td>6021</td>
      <td>13000</td>
      <td>60</td>
      <td>330</td>
      <td>0.18</td>
      <td>640</td>
      <td>0</td>
      <td>PAID_UP</td>
    </tr>
    <tr>
      <td>2</td>
      <td>acc_00001373</td>
      <td>F</td>
      <td>39</td>
      <td>12832</td>
      <td>13000</td>
      <td>60</td>
      <td>296</td>
      <td>0.13</td>
      <td>820</td>
      <td>0</td>
      <td>PAID_UP</td>
    </tr>
    <tr>
      <td>3</td>
      <td>acc_00001686</td>
      <td>F</td>
      <td>33</td>
      <td>4867</td>
      <td>5000</td>
      <td>36</td>
      <td>191</td>
      <td>0.22</td>
      <td>540</td>
      <td>0</td>
      <td>PAID_UP</td>
    </tr>
    <tr>
      <td>4</td>
      <td>acc_00001733</td>
      <td>F</td>
      <td>23</td>
      <td>5107</td>
      <td>22000</td>
      <td>36</td>
      <td>818</td>
      <td>0.20</td>
      <td>580</td>
      <td>11314</td>
      <td>LIVE</td>
    </tr>
  </tbody>
</table>

<h2 id="1-exploratory-data-analysis">1. Exploratory Data Analysis</h2>

<ul>
  <li><code class="language-plaintext highlighter-rouge">account_no</code> column is just an unique identifier and has no predictive power, we will drop it</li>
  <li><code class="language-plaintext highlighter-rouge">outstanding_balance</code> will have value <code class="language-plaintext highlighter-rouge">=0</code> for <code class="language-plaintext highlighter-rouge">PAID_UP</code> status. Hence we will need to drop this column as well to prevent data leakage.</li>
</ul>

<h4 id="11-remove-live-rows">1.1 Remove <code class="language-plaintext highlighter-rouge">LIVE</code> rows</h4>

<ul>
  <li>As the business goal of this task is to estimate value of current loans, we will drop rows where <code class="language-plaintext highlighter-rouge">status</code> column is <code class="language-plaintext highlighter-rouge">LIVE</code>.</li>
  <li>We will train the model on terminal loan statuses and run the prediction on this <code class="language-plaintext highlighter-rouge">LIVE</code> dataset later.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_full_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'status'</span><span class="p">]</span><span class="o">==</span><span class="s">'LIVE'</span><span class="p">].</span><span class="n">index</span><span class="p">)</span>
<span class="n">df_live</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'status'</span><span class="p">]</span><span class="o">==</span><span class="s">'LIVE'</span><span class="p">]</span>
</code></pre></div></div>

<p>The proportion of DEFAULT is about 7%. This level is used to sense check with the final model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_full_train</span><span class="p">[</span><span class="s">'status'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">PAID_UP</span>    <span class="mf">0.931</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">DEFAULT</span>    <span class="mf">0.069</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Name</span><span class="p">:</span> <span class="n">status</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</code></pre></div></div>

<p>Since the target variable is either <code class="language-plaintext highlighter-rouge">PAID_UP</code> or <code class="language-plaintext highlighter-rouge">DEFAULT</code>, we can simply replace the values. Since we are interested in <code class="language-plaintext highlighter-rouge">DEFAULT</code>, I will make it the positive class with value <code class="language-plaintext highlighter-rouge">1</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_full_train</span><span class="p">[</span><span class="s">'status'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_full_train</span><span class="p">[</span><span class="s">'status'</span><span class="p">].</span><span class="nf">map</span><span class="p">({</span>
    <span class="s">'PAID_UP'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s">'DEFAULT'</span><span class="p">:</span> <span class="mi">1</span>
<span class="p">})</span>

<span class="n">df_full_train</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>**index**</th>
      <th>**account_no**</th>
      <th>**gender**</th>
      <th>**age**</th>
      <th>**income**</th>
      <th>**loan_amount**</th>
      <th>**term**</th>
      <th>**installment_amount**</th>
      <th>**interest_rate**</th>
      <th>**credit_score_at_application**</th>
      <th>**outstanding_balance**</th>
      <th>**status**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>acc_00000316</td>
      <td>F</td>
      <td>18</td>
      <td>12143</td>
      <td>47000</td>
      <td>60</td>
      <td>1045</td>
      <td>0.12</td>
      <td>860</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>acc_00000422</td>
      <td>F</td>
      <td>18</td>
      <td>6021</td>
      <td>13000</td>
      <td>60</td>
      <td>330</td>
      <td>0.18</td>
      <td>640</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>acc_00001373</td>
      <td>F</td>
      <td>39</td>
      <td>12832</td>
      <td>13000</td>
      <td>60</td>
      <td>296</td>
      <td>0.13</td>
      <td>820</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>acc_00001686</td>
      <td>F</td>
      <td>33</td>
      <td>4867</td>
      <td>5000</td>
      <td>36</td>
      <td>191</td>
      <td>0.22</td>
      <td>540</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>5</td>
      <td>acc_00002114</td>
      <td>M</td>
      <td>38</td>
      <td>9328</td>
      <td>25000</td>
      <td>36</td>
      <td>904</td>
      <td>0.18</td>
      <td>630</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">df_full_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'account_no'</span><span class="p">,</span> <span class="s">'outstanding_balance'</span><span class="p">,</span> <span class="s">'status'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_full_train</span><span class="p">[</span><span class="s">'status'</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="12-univariate-distributions-of-features">1.2 Univariate distributions of features</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">NUMERICAL</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s">'number'</span><span class="p">).</span><span class="n">columns</span><span class="p">)</span>
<span class="n">CATEGORICAL</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s">'object'</span><span class="p">).</span><span class="n">columns</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">NUMERICAL</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">CATEGORICAL</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="s">'age'</span><span class="p">,</span> <span class="s">'income'</span><span class="p">,</span> <span class="s">'loan_amount'</span><span class="p">,</span> <span class="s">'term'</span><span class="p">,</span> <span class="s">'installment_amount'</span><span class="p">,</span> <span class="s">'interest_rate'</span><span class="p">,</span> <span class="s">'credit_score_at_application'</span><span class="p">,</span> <span class="s">'outstanding_balance'</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="s">'account_no'</span><span class="p">,</span> <span class="s">'gender'</span><span class="p">,</span> <span class="s">'status'</span><span class="p">]</span>
</code></pre></div></div>

<p>To understand the distributions of numerical data, we can plot individual historgrams</p>
<ul>
  <li>Since I want to interpret the coefficients, I will just leave them as is for the base model instead of transforming.</li>
  <li>For this dataset, we don’t have issue with outliers except for <code class="language-plaintext highlighter-rouge">outstanding_balance</code>. But we will not be using this feature anyway.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">NUMERICAL</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">idx</span><span class="o">%</span><span class="mi">4</span><span class="p">]</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="n">col_name</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col_name</span><span class="p">],</span> <span class="n">ec</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">col_name</span><span class="p">].</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/predict-loan-default/notebook_18_0.png" alt="png" /></p>

<h4 id="13-bivariate-relationship-between-features-and-target-variable">1.3 Bivariate relationship between features and target variable</h4>

<ul>
  <li>To understand the relationship between each individual feature with the target, we can plot a correlation chart. However, since the target is binary, I will use boxplot instead.</li>
  <li>In the charts below, <code class="language-plaintext highlighter-rouge">income</code>, <code class="language-plaintext highlighter-rouge">interest_rate</code> and <code class="language-plaintext highlighter-rouge">credit_score_at_application</code> are the strongest predictors of whether the loanee will default.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig2</span><span class="p">,</span> <span class="n">axes2</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">NUMERICAL</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">NUMERICAL</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span>
        <span class="n">df_full_train</span><span class="p">[[</span><span class="n">col_name</span><span class="p">,</span> <span class="s">'status'</span><span class="p">]],</span>
        <span class="n">x</span><span class="o">=</span><span class="s">'status'</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">col_name</span><span class="p">,</span>
        <span class="n">showfliers</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axes2</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    
    <span class="n">axes2</span><span class="p">[</span><span class="n">idx</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s">'is_defaulted'</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes2</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

<span class="n">fig2</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/predict-loan-default/notebook_20_0.png" alt="png" /></p>

<h2 id="2-manual-fitting">2. Manual fitting</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="21-preprocessing">2.1 Preprocessing</h4>

<h4 id="211-check-for-nannulls-values">2.1.1 Check for NaN/Nulls values</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">gender</span>                         <span class="mi">0</span>
    <span class="n">age</span>                            <span class="mi">0</span>
    <span class="n">income</span>                         <span class="mi">0</span>
    <span class="n">loan_amount</span>                    <span class="mi">0</span>
    <span class="n">term</span>                           <span class="mi">0</span>
    <span class="n">installment_amount</span>             <span class="mi">0</span>
    <span class="n">interest_rate</span>                  <span class="mi">0</span>
    <span class="n">credit_score_at_application</span>    <span class="mi">0</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">int64</span>
</code></pre></div></div>

<h4 id="212-categorical-data">2.1.2 Categorical data</h4>

<p>We will use one-hot encoding for <code class="language-plaintext highlighter-rouge">gender</code>. <code class="language-plaintext highlighter-rouge">0</code> represents Female, <code class="language-plaintext highlighter-rouge">1</code> represents Male</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gender_encoder</span> <span class="o">=</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s">'first'</span><span class="p">)</span>
<span class="n">gender_encoder</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="s">'gender'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">gender_encoder</span><span class="p">.</span><span class="n">categories_</span>

<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="nf">array</span><span class="p">([</span><span class="s">'F'</span><span class="p">,</span> <span class="s">'M'</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># encode column
</span><span class="n">encoded_gender</span> <span class="o">=</span> <span class="n">gender_encoder</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="s">'gender'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)).</span><span class="nf">toarray</span><span class="p">()</span>

<span class="c1"># convert encoded columns into dataframe
</span><span class="n">encoded_gender_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span>
    <span class="n">encoded_gender</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">gender_encoder</span><span class="p">.</span><span class="nf">get_feature_names_out</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># merge original df with encoded df
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span>
    <span class="p">[</span><span class="n">X_train</span><span class="p">,</span> <span class="n">encoded_gender_df</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># drop original column
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'gender'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>**index**</th>
      <th>**age**</th>
      <th>**income**</th>
      <th>**loan_amount**</th>
      <th>**term**</th>
      <th>**installment_amount**</th>
      <th>**interest_rate**</th>
      <th>**credit_score_at_application**</th>
      <th>**x0_M**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>33</td>
      <td>16685</td>
      <td>55000</td>
      <td>60</td>
      <td>1223</td>
      <td>0.12</td>
      <td>850</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>27</td>
      <td>15050</td>
      <td>28000</td>
      <td>24</td>
      <td>1331</td>
      <td>0.13</td>
      <td>840</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>50</td>
      <td>40203</td>
      <td>62000</td>
      <td>48</td>
      <td>1345</td>
      <td>0.02</td>
      <td>1000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>26</td>
      <td>13754</td>
      <td>39000</td>
      <td>48</td>
      <td>1066</td>
      <td>0.14</td>
      <td>810</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>30</td>
      <td>11830</td>
      <td>31000</td>
      <td>60</td>
      <td>705</td>
      <td>0.13</td>
      <td>810</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>

<h4 id="213-numerical-data">2.1.3 Numerical data</h4>

<p>For the base model, we keep numerical data intact.</p>

<h3 id="22-fitting-logistics-regression-model">2.2 Fitting Logistics Regression Model</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">log_reg</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1_000</span><span class="p">)</span>
<span class="n">log_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style>
<div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked="" /><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">LogisticRegression</label><div class="sk-toggleable__content"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>

<h4 id="23-model-coefficients">2.3 Model coefficients</h4>

<p>An advantage of Logistics Regression is that the coefficients are white box, making it easier for stakeholders to understand why the model makes a certain prediction.</p>

<p>We can write the full formula based on the fitted model’s intercept and coefficients</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">log_reg</span><span class="p">.</span><span class="n">intercept_</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">array</span><span class="p">([</span><span class="mf">1.22179855</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_coefficients</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span>
    <span class="nf">list</span><span class="p">(</span><span class="n">log_reg</span><span class="p">.</span><span class="n">feature_names_in_</span><span class="p">),</span>
    <span class="nf">list</span><span class="p">(</span><span class="n">log_reg</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="p">)</span>

<span class="n">model_coefficients</span>

<span class="o">&gt;&gt;&gt;</span> <span class="p">{</span><span class="s">'age'</span><span class="p">:</span> <span class="mf">0.057494705504614954</span><span class="p">,</span>
     <span class="s">'income'</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.0032484557471085074</span><span class="p">,</span>
     <span class="s">'loan_amount'</span><span class="p">:</span> <span class="o">-</span><span class="mf">2.8753044215366256e-05</span><span class="p">,</span>
     <span class="s">'term'</span><span class="p">:</span> <span class="mf">0.022543857502140222</span><span class="p">,</span>
     <span class="s">'installment_amount'</span><span class="p">:</span> <span class="mf">0.0009745065842801654</span><span class="p">,</span>
     <span class="s">'interest_rate'</span><span class="p">:</span> <span class="mf">0.6331692246041164</span><span class="p">,</span>
     <span class="s">'credit_score_at_application'</span><span class="p">:</span> <span class="mf">0.0165512445820803</span><span class="p">,</span>
     <span class="s">'x0_M'</span><span class="p">:</span> <span class="mf">7.976349551593769</span><span class="p">}</span>

</code></pre></div></div>

<p>Hence the full formula is:</p>

<p>$$ z = 1.222 + age * 0.057 +income * -0.003 +loan_amount * -0.0 +term * 0.023 +installment_amount * 0.001 +interest_rate * 0.633 +credit_score_at_application * 0.017 +x0_M * 7.976 $$</p>

<p>$$ prob(default) = \frac{1}{1 + e^{-z}} $$</p>

<p>To make a sample prediction, we can apply the above formula as follow:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'age'</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span>
    <span class="s">'income'</span><span class="p">:</span> <span class="mi">10_000</span><span class="p">,</span>
    <span class="s">'loan_amount'</span><span class="p">:</span> <span class="mi">20_000</span><span class="p">,</span>
    <span class="s">'term'</span><span class="p">:</span> <span class="mi">60</span><span class="p">,</span>
    <span class="s">'installment_amount'</span><span class="p">:</span> <span class="mi">1_000</span><span class="p">,</span>
    <span class="s">'interest_rate'</span><span class="p">:</span> <span class="mf">0.15</span><span class="p">,</span>
    <span class="s">'credit_score_at_application'</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
    <span class="s">'x0_M'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">e</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="n">n</span><span class="p">))</span>

<span class="n">z</span> <span class="o">=</span> <span class="mf">1.22179855</span> <span class="o">+</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">model_coefficients</span><span class="p">.</span><span class="nf">values</span><span class="p">()))</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">sample_data</span><span class="p">.</span><span class="nf">values</span><span class="p">()))).</span><span class="nf">sum</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="s">'probability of default for sample data'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">probability</span> <span class="n">of</span> <span class="n">default</span> <span class="k">for</span> <span class="n">sample</span> <span class="n">data</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mf">0.0015414024478882305</span>
</code></pre></div></div>

<p>To verify that the function works, we can compare predicted default probability by using the model’s <code class="language-plaintext highlighter-rouge">.predict()</code> method</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="n">log_reg</span><span class="p">.</span><span class="nf">predict_proba</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">sample_data</span><span class="p">.</span><span class="nf">values</span><span class="p">())).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">))[:,</span> <span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="mf">0.0015414024462043266</span>
</code></pre></div></div>

<h4 id="24-making-predictions">2.4 Making predictions</h4>

<p>Now that we understand how the model works, let’s see how it performs on test data.</p>

<p>In order to run the model on test data, we need to perform the same transformation steps above.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># encode column
</span><span class="n">encoded_gender</span> <span class="o">=</span> <span class="n">gender_encoder</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="s">'gender'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)).</span><span class="nf">toarray</span><span class="p">()</span>

<span class="c1"># convert encoded columns into dataframe
</span><span class="n">encoded_gender_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span>
    <span class="n">encoded_gender</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">gender_encoder</span><span class="p">.</span><span class="nf">get_feature_names_out</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># merge original df with encoded df
</span><span class="n">X_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span>
    <span class="p">[</span><span class="n">X_test</span><span class="p">,</span> <span class="n">encoded_gender_df</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># drop original column
</span><span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'gender'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>**index**</th>
      <th>**age**</th>
      <th>**income**</th>
      <th>**loan_amount**</th>
      <th>**term**</th>
      <th>**installment_amount**</th>
      <th>**interest_rate**</th>
      <th>**credit_score_at_application**</th>
      <th>**x0_M**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>37</td>
      <td>14163</td>
      <td>28000</td>
      <td>60</td>
      <td>652</td>
      <td>0.14</td>
      <td>780</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>27</td>
      <td>10769</td>
      <td>33000</td>
      <td>24</td>
      <td>1584</td>
      <td>0.14</td>
      <td>790</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>28</td>
      <td>10747</td>
      <td>34000</td>
      <td>48</td>
      <td>929</td>
      <td>0.14</td>
      <td>790</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>22</td>
      <td>14439</td>
      <td>49000</td>
      <td>24</td>
      <td>2284</td>
      <td>0.11</td>
      <td>910</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>32</td>
      <td>6400</td>
      <td>17000</td>
      <td>36</td>
      <td>649</td>
      <td>0.22</td>
      <td>540</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_preds</span> <span class="o">=</span> <span class="n">log_reg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_preds</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">...,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<h4 id="25-evaluate-model">2.5 Evaluate model</h4>

<p>Accuracy, Recall, Precision, f1-score</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">evaluate_model</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>    
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'accuracy'</span><span class="p">:</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span>
        <span class="s">'recall'</span><span class="p">:</span> <span class="nf">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span>
        <span class="s">'precision'</span><span class="p">:</span> <span class="nf">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span>
        <span class="s">'f1_score'</span><span class="p">:</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">result</span>

<span class="nf">evaluate_model</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">{</span><span class="s">'accuracy'</span><span class="p">:</span> <span class="mf">0.9705</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'recall'</span><span class="p">:</span> <span class="mf">0.8035714285714286</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'precision'</span><span class="p">:</span> <span class="mf">0.8385093167701864</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'f1_score'</span><span class="p">:</span> <span class="mf">0.8206686930091185</span><span class="p">}</span>
</code></pre></div></div>

<p>ROC curve</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thres</span> <span class="o">=</span> <span class="nf">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">log_reg</span><span class="p">.</span><span class="nf">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'logistics regression model'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1_000</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1_000</span><span class="p">),</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'random guess'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s">'False positive rate'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s">'True positive rate'</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="/assets/images/posts/predict-loan-default/notebook_51_1.png" alt="png" /></p>

<p>At this point we have a working model.</p>

<p>However in practice we rarely build just 1 model. We will need to experiment with different types of tranformation, and tuning hyperparameters</p>

<p>As the number of transformations and parameters increases, we will need to keep track of more objects. This is cumbersome and prone to error. That’s why we will use a Pipeline.</p>

<h2 id="3-using-pipelines">3. Using Pipelines</h2>

<p>We can build the same model as above using fewer lines of code thanks to Pipeline</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="31-column-transformers">3.1 Column transformers</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># define the column transformer to encode gender column
</span><span class="n">column_transformer</span> <span class="o">=</span> <span class="nc">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s">'encoder'</span><span class="p">,</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s">'first'</span><span class="p">),</span> <span class="p">[</span><span class="s">'gender'</span><span class="p">])</span>
    <span class="p">],</span>
    <span class="n">remainder</span><span class="o">=</span><span class="s">'passthrough'</span>
<span class="p">)</span>
</code></pre></div></div>

<h4 id="32-build-and-fit-pipeline">3.2 Build and fit pipeline</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># define the pipeline with column transformer and logistic regression
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s">'preprocessor'</span><span class="p">,</span> <span class="n">column_transformer</span><span class="p">),</span>
    <span class="p">(</span><span class="s">'classifier'</span><span class="p">,</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1_000</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># fit the pipeline to the training data
</span><span class="n">pipeline</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">preds</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nf">evaluate_model</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="p">{</span><span class="s">'accuracy'</span><span class="p">:</span> <span class="mf">0.9705</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'recall'</span><span class="p">:</span> <span class="mf">0.8035714285714286</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'precision'</span><span class="p">:</span> <span class="mf">0.8385093167701864</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'f1_score'</span><span class="p">:</span> <span class="mf">0.8206686930091185</span><span class="p">}</span>
</code></pre></div></div>

<p>Here we can verify that pipeline produces the same result as manual steps by comparing predicted output and metrics.</p>

<h4 id="33-cross-validation-with-pipeline">3.3 Cross validation with Pipeline</h4>

<ul>
  <li>
    <p>Cross-validation is a technique that is used to evaluate the performance of the model. In cross-validation, the data is split into k-folds, where each fold is used for testing at least once. For example, if 5-fold cross-validation is used, then in the first iteration, fold 1 may be used for testing and folds 2–5 for training. In the second iteration, fold 2 may be used for testing, the rest of the folds for training the model, and so on until all the folds are used for testing at least once.</p>
  </li>
  <li>
    <p>K-fold cross-validation can be especially useful when the dataset is small or imbalanced, as it allows for the model to be evaluated on all of the data, even if some observations have low representation in the dataset.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define the cross-validation strategy
</span><span class="n">cv</span> <span class="o">=</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Perform cross-validation
</span><span class="n">acc_scores</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>

<span class="c1"># Compute the mean and standard deviation of the scores
</span><span class="nf">print</span><span class="p">(</span><span class="s">"Accuracy: %0.2f (+/- %0.2f)"</span> <span class="o">%</span> <span class="p">(</span><span class="n">acc_scores</span><span class="p">.</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">acc_scores</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.97</span> <span class="p">(</span><span class="o">+/-</span> <span class="mf">0.02</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="34-hyperparameters-tuning">3.4 Hyperparameters tuning</h4>

<p>Hyperparameter tuning refers to the process of selecting the best hyperparameters for a machine learning model in order to achieve optimal performance. In the case of logistic regression classification, hyperparameters are values that are set before the learning process begins and affect the behavior of the model.</p>

<p>Here are some hyperparameters that we can tune for Logistics Regression:</p>
<ul>
  <li>
    <p>Regularization strength: Regularization helps to prevent overfitting of the model by penalizing large coefficients. The regularization strength hyperparameter controls the amount of penalization applied.</p>
  </li>
  <li>
    <p>Solver: The solver is the algorithm used to optimize the logistic regression objective function. There are several solvers available, such as ‘newton-cg’, ‘lbfgs’, and ‘liblinear’, each with different strengths and weaknesses.</p>
  </li>
  <li>
    <p>Maximum number of iterations: The maximum number of iterations determines the maximum number of iterations for the solver to converge.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">column_transformer</span> <span class="o">=</span> <span class="nc">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s">'categorical_encoder'</span><span class="p">,</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s">'first'</span><span class="p">),</span> <span class="p">[</span><span class="s">'gender'</span><span class="p">]),</span>
        <span class="p">(</span><span class="s">'numerical_scaler'</span><span class="p">,</span> <span class="nc">StandardScaler</span><span class="p">(),</span> <span class="n">NUMERICAL</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="p">],</span>
    <span class="n">remainder</span><span class="o">=</span><span class="s">'passthrough'</span>
<span class="p">)</span>

<span class="n">my_pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s">'preprocessor'</span><span class="p">,</span> <span class="n">column_transformer</span><span class="p">),</span>
    <span class="p">(</span><span class="s">'classifier'</span><span class="p">,</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10_000</span><span class="p">))</span>
<span class="p">])</span>


<span class="c1"># Define the hyperparameters to tune
</span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'preprocessor__numerical_scaler__with_mean'</span><span class="p">:</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">],</span>
    <span class="s">'classifier__penalty'</span><span class="p">:</span> <span class="p">[</span><span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">],</span>
    <span class="s">'classifier__C'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="s">'classifier__solver'</span><span class="p">:</span> <span class="p">[</span><span class="s">'liblinear'</span><span class="p">,</span> <span class="s">'saga'</span><span class="p">]</span>
<span class="p">}</span>


<span class="c1"># Create a grid search object
</span><span class="n">grid_search</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">my_pipeline</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="c1"># Fit the grid search object on the data
</span><span class="n">grid_search</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="s">"Best parameters: "</span><span class="p">,</span> <span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="s">"Best cross-validation score: "</span><span class="p">,</span> <span class="n">grid_search</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">Best</span> <span class="n">parameters</span><span class="p">:</span>  <span class="p">{</span><span class="s">'classifier__C'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'classifier__penalty'</span><span class="p">:</span> <span class="s">'l1'</span><span class="p">,</span> <span class="s">'classifier__solver'</span><span class="p">:</span> <span class="s">'saga'</span><span class="p">,</span> <span class="s">'preprocessor__numerical_scaler__with_mean'</span><span class="p">:</span> <span class="bp">True</span><span class="p">}</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">Best</span> <span class="n">cross</span><span class="o">-</span><span class="n">validation</span> <span class="n">score</span><span class="p">:</span>  <span class="mf">0.9728653846153847</span>
</code></pre></div></div>

<h4 id="35-retrain-piepline-on-the-best-params">3.5 Retrain piepline on the best params</h4>

<p>Training the model on the best params give us improved metrics</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">column_transformer</span> <span class="o">=</span> <span class="nc">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s">'categorical_encoder'</span><span class="p">,</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s">'first'</span><span class="p">),</span> <span class="p">[</span><span class="s">'gender'</span><span class="p">]),</span>
        <span class="p">(</span><span class="s">'numerical_scaler'</span><span class="p">,</span> <span class="nc">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> <span class="n">NUMERICAL</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="p">],</span>
    <span class="n">remainder</span><span class="o">=</span><span class="s">'passthrough'</span>
<span class="p">)</span>

<span class="n">best_pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s">'preprocessor'</span><span class="p">,</span> <span class="n">column_transformer</span><span class="p">),</span>
    <span class="p">(</span><span class="s">'classifier'</span><span class="p">,</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s">'l1'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">6_000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s">'saga'</span><span class="p">))</span>
<span class="p">])</span>


<span class="c1"># fit the pipeline to the training data
</span><span class="n">best_pipeline</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">preds</span> <span class="o">=</span> <span class="n">best_pipeline</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nf">evaluate_model</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="p">{</span><span class="s">'accuracy'</span><span class="p">:</span> <span class="mf">0.971</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'recall'</span><span class="p">:</span> <span class="mf">0.8214285714285714</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span> <span class="s">'precision'</span><span class="p">:</span> <span class="mf">0.8313253012048193</span><span class="p">,</span>
<span class="o">&gt;&gt;&gt;</span><span class="s">'f1_score'</span><span class="p">:</span> <span class="mf">0.8263473053892216</span><span class="p">}</span>

</code></pre></div></div>

<h2 id="4-predict-model-on-live-loans-data">4. Predict model on <code class="language-plaintext highlighter-rouge">LIVE</code> loans data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_live</span> <span class="o">=</span> <span class="n">df_live</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'account_no'</span><span class="p">,</span> <span class="s">'status'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df_live</span> <span class="o">=</span> <span class="n">df_live</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_live</span><span class="p">[</span><span class="s">'predicted_default'</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_pipeline</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">df_live</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'outstanding_balance'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">df_live</span><span class="p">[</span><span class="s">'default_prob'</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_pipeline</span><span class="p">.</span><span class="nf">predict_proba</span><span class="p">(</span><span class="n">df_live</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="s">'outstanding_balance'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))[:,</span> <span class="mi">1</span><span class="p">].</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_live</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>**index**</th>
      <th>**gender**</th>
      <th>**age**</th>
      <th>**income**</th>
      <th>**loan_amount**</th>
      <th>**term**</th>
      <th>**installment_amount**</th>
      <th>**interest_rate**</th>
      <th>**credit_score_at_application**</th>
      <th>**outstanding_balance**</th>
      <th>**predicted_default**</th>
      <th>**default_prob**</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>F</td>
      <td>23</td>
      <td>5107</td>
      <td>22000</td>
      <td>36</td>
      <td>818</td>
      <td>0.20</td>
      <td>580</td>
      <td>11314</td>
      <td>0</td>
      <td>0.043</td>
    </tr>
    <tr>
      <td>1</td>
      <td>F</td>
      <td>40</td>
      <td>15659</td>
      <td>33000</td>
      <td>48</td>
      <td>853</td>
      <td>0.11</td>
      <td>880</td>
      <td>5637</td>
      <td>0</td>
      <td>0.000</td>
    </tr>
    <tr>
      <td>2</td>
      <td>M</td>
      <td>25</td>
      <td>15660</td>
      <td>15000</td>
      <td>48</td>
      <td>395</td>
      <td>0.12</td>
      <td>860</td>
      <td>6039</td>
      <td>0</td>
      <td>0.000</td>
    </tr>
    <tr>
      <td>3</td>
      <td>F</td>
      <td>30</td>
      <td>4208</td>
      <td>15000</td>
      <td>48</td>
      <td>481</td>
      <td>0.23</td>
      <td>530</td>
      <td>2817</td>
      <td>0</td>
      <td>0.297</td>
    </tr>
    <tr>
      <td>4</td>
      <td>F</td>
      <td>18</td>
      <td>6535</td>
      <td>12000</td>
      <td>48</td>
      <td>346</td>
      <td>0.17</td>
      <td>660</td>
      <td>3120</td>
      <td>0</td>
      <td>0.001</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">expected_book_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_live</span><span class="p">[</span><span class="s">'outstanding_balance'</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">df_live</span><span class="p">[</span><span class="s">'default_prob'</span><span class="p">])).</span><span class="nf">sum</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"total outstanding balance =</span><span class="se">\t</span><span class="si">{</span><span class="n">df_live</span><span class="p">[</span><span class="s">'outstanding_balance'</span><span class="p">].</span><span class="nf">sum</span><span class="p">()</span><span class="si">:</span><span class="p">,.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"expected recoverable value =</span><span class="se">\t</span><span class="si">{</span><span class="n">expected_book_value</span><span class="si">:</span><span class="p">,.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">total</span> <span class="n">outstanding</span> <span class="n">balance</span> <span class="o">=</span>	<span class="mi">24</span><span class="p">,</span><span class="mi">622</span><span class="p">,</span><span class="mf">111.00</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">expected</span> <span class="n">recoverable</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">23</span><span class="p">,</span><span class="mi">809</span><span class="p">,</span><span class="mf">056.25</span>
</code></pre></div></div>

<h2 id="5-summary">5. Summary</h2>
<p><strong>What we did</strong></p>
<ul>
  <li>We built a Logistics Regression for a classification of loan default.</li>
  <li>We chose Logistics Regression because it’s a white box model with clear parameters, making iteasier to explain to business stakeholders.</li>
  <li>We used sklearn’s Pipeline to make it easy to do Cross Validation and Hyperparameters Tuning</li>
</ul>

<p><strong>Improvement ideas</strong></p>
<ul>
  <li>For the sake of simplicity I have not factored in time value of money. But this can be done by discounting each payment according to their expected due date.</li>
  <li>By default, <code class="language-plaintext highlighter-rouge">pipeline.predict()</code> has a decision threshold of <code class="language-plaintext highlighter-rouge">0.5</code>. Meaning that if <code class="language-plaintext highlighter-rouge">pipeline.predict_proba()</code> is above <code class="language-plaintext highlighter-rouge">0.5</code> then the data will be classified as default.
    <ul>
      <li>At a recall score of <code class="language-plaintext highlighter-rouge">0.82</code> we expect about 8 out of 10 defaults are identified.</li>
      <li>We can improve recall by lowering the decision threshold. The cost will be more false positive (non-default classified as default)</li>
      <li>Depending on the business objective, we can fine tune threshold level. If we want to be conservative with our estimate, then higher recall might be more acceptable.</li>
    </ul>
  </li>
  <li>We can also explore ensemble methods, such as xgboost, as it works well with tabular data</li>
</ul>]]></content><author><name>Vo Duy Do</name></author><category term="sklearn" /><category term="classification" /><summary type="html"><![CDATA[Fitting a statistical model to historical credit data and estimate the value of current loans. Along with model building, I will demonstrate the use of sklearn's Pipeline as a more convenient approach for Feature Enginerring, Cross Validation and Hyperparameters Tuning]]></summary></entry><entry><title type="html">Guessing user drawn digit</title><link href="https://dobeok.github.io//jekyll-theme-yat/2023/02/15/guess-digits.html" rel="alternate" type="text/html" title="Guessing user drawn digit" /><published>2023-02-15T05:00:00+00:00</published><updated>2023-02-15T05:00:00+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2023/02/15/guess-digits</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2023/02/15/guess-digits.html"><![CDATA[<p>In this post I made a fun game of drawing a number, and challenging the model to guess it correctly. The model itself is a Convolutional Neural Network (CNN) model, built using the MNIST digits datasets.</p>

<p>Here I want to combine it with a streamlit apps that can take live user inpu, making the inference process more interactive.</p>

<p><a href="https://dobeok-guess-digit-app-app-aggm7n.streamlit.app/">Try on Streamlit</a></p>

<video controls="" autoplay="" height="480">
  <source src="/assets/images/posts/guess-digit/guess-digit-demo.mov" type="video/mp4" />
  Your browser does not support the video tag.
</video>

<h2 id="i-streamlit-code-front-end">I. Streamlit code (front-end)</h2>

<p>The full code can be found in <a href="https://github.com/dobeok/guess-digit-app">my repo</a>. Here’s a minimal code to highlight the main logic.</p>

<script src="https://gist.github.com/dobeok/953becc81efecf5d8f1554e6fdd1c103.js"></script>

<h2 id="iimodel-building-code-back-end">II.Model building code (back-end)</h2>

<h3 id="0-imports">0. Imports</h3>

<script src="https://gist.github.com/dobeok/bfd56bdcfe4230218129beb5c6e45082.js"></script>

<h3 id="1-load--explore-data">1. Load &amp; explore data</h3>

<script src="https://gist.github.com/dobeok/209519729f6b1353684d4905e0448543.js"></script>

<h4 id="11-sample-different-ways-to-write-each-number">1.1 Sample different ways to write each number</h4>

<script src="https://gist.github.com/dobeok/2cb2abed013652802bf4f748bd38613c.js"></script>

<p><img src="/assets/images/posts/guess-digit/model_files/model_sample_train_data.png" alt="png" /></p>

<h4 id="12-check-if-classes-are-balanced">1.2 Check if classes are balanced</h4>

<script src="https://gist.github.com/dobeok/3a44b2f3248d545388a315a1013e9a67.js"></script>

<p><img src="/assets/images/posts/guess-digit/model_files/model_7_1.png" alt="png" /></p>

<h3 id="2-transform-data">2 Transform data</h3>

<script src="https://gist.github.com/dobeok/962492ac801daa93b47743d33797b329.js"></script>

<h3 id="3-model">3. Model</h3>

<script src="https://gist.github.com/dobeok/4d988f917b3ff697386510a755dd64bb.js"></script>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
    Model: "sequential"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     conv2d (Conv2D)             (None, 26, 26, 32)        320       
                                                                     
     max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         
     )                                                               
                                                                     
     conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     
                                                                     
     max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         
     2D)                                                             
                                                                     
     flatten (Flatten)           (None, 1600)              0         
                                                                     
     dropout (Dropout)           (None, 1600)              0         
                                                                     
     dense (Dense)               (None, 10)                16010     
                                                                     
    =================================================================
    Total params: 34,826
    Trainable params: 34,826
    Non-trainable params: 0
    _________________________________________________________________
</code></pre></div></div>

<script src="https://gist.github.com/dobeok/9a482db762760093a8a2d40ec85a52cf.js"></script>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Epoch 1/15


    2023-02-19 22:15:15.668285: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
    2023-02-19 22:15:15.874289: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.


    422/422 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.8868

    2023-02-19 22:15:23.874575: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.


    422/422 [==============================] - 9s 17ms/step - loss: 0.3702 - accuracy: 0.8868 - val_loss: 0.0942 - val_accuracy: 0.9743
    Epoch 2/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.1146 - accuracy: 0.9653 - val_loss: 0.0643 - val_accuracy: 0.9823
    Epoch 3/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0856 - accuracy: 0.9739 - val_loss: 0.0514 - val_accuracy: 0.9865
    Epoch 4/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0716 - accuracy: 0.9789 - val_loss: 0.0483 - val_accuracy: 0.9872
    Epoch 5/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0639 - accuracy: 0.9797 - val_loss: 0.0446 - val_accuracy: 0.9868
    Epoch 6/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0573 - accuracy: 0.9829 - val_loss: 0.0391 - val_accuracy: 0.9902
    Epoch 7/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0508 - accuracy: 0.9841 - val_loss: 0.0368 - val_accuracy: 0.9907
    Epoch 8/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 0.0358 - val_accuracy: 0.9890
    Epoch 9/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0441 - accuracy: 0.9869 - val_loss: 0.0369 - val_accuracy: 0.9897
    Epoch 10/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0413 - accuracy: 0.9871 - val_loss: 0.0344 - val_accuracy: 0.9898
    Epoch 11/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0345 - val_accuracy: 0.9907
    Epoch 12/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0359 - accuracy: 0.9886 - val_loss: 0.0335 - val_accuracy: 0.9905
    Epoch 13/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 0.0350 - val_accuracy: 0.9895
    Epoch 14/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.0314 - val_accuracy: 0.9913
    Epoch 15/15
    422/422 [==============================] - 6s 15ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0299 - val_accuracy: 0.9917
</code></pre></div></div>

<script src="https://gist.github.com/dobeok/d270ab600266430703e6e39e537d7e8a.js"></script>

<p><img src="/assets/images/posts/guess-digit/model_files/model_21_0.png" alt="png" /></p>

<h3 id="4-evaluate-performance">4. Evaluate performance</h3>

<h4 id="41-predict-on-test-data">4.1 Predict on test data</h4>

<script src="https://gist.github.com/dobeok/e87ae62735b7cb6676f35fbbd8d30524.js"></script>

<h4 id="42-confusion-matrix">4.2 Confusion matrix</h4>

<script src="https://gist.github.com/dobeok/6a83910d6aed3a30b0b17412ac8a7b10.js"></script>

<p><img src="/assets/images/posts/guess-digit/model_files/model_33_1.png" alt="png" /></p>

<p>Observations:</p>
<ul>
  <li>Majority of predictions are on the correct diagonal</li>
  <li>3 and 5; 4 and 9 are commonly mistaken pairs, which is understandable because even human might make the same mistakes</li>
</ul>

<h3 id="5-whats-next">5. What’s next?</h3>

<ul>
  <li>Augment data. The images in the tranining datasets are quite small (28 x 28 pixels) so I had to downsize the input image. Otherwise the drawing canvas would be very small. There are some augmentation techniques that I think will improve the model:
    <ul>
      <li>Translation</li>
      <li>Rotation</li>
      <li>Scaling</li>
    </ul>
  </li>
</ul>]]></content><author><name>Vo Duy Do</name></author><category term="keras" /><category term="streamlit" /><summary type="html"><![CDATA[Using CNN to build a digit guessing game. The model is trained using Keras and GUI is created using Streamlit]]></summary></entry><entry><title type="html">Analyzing Vietnam’s high school graduation exam results</title><link href="https://dobeok.github.io//jekyll-theme-yat/2023/01/31/vn-exam.html" rel="alternate" type="text/html" title="Analyzing Vietnam’s high school graduation exam results" /><published>2023-01-31T05:00:00+00:00</published><updated>2023-01-31T05:00:00+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2023/01/31/vn-exam</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2023/01/31/vn-exam.html"><![CDATA[<h2 id="0-introduction">0. Introduction</h2>

<ul>
  <li>
    <p>The Vietnamese high school graduation exam, also known as the National High School Exam, is a standardized test taken by high school students in Vietnam. It is used to determine whether students have achieved a sufficient level of knowledge and skills in order to graduate from high school and is considered a crucial factor in their future academic and career prospects. The test covers subjects such as mathematics, literature, physics, chemistry, biology, history, and geography.</p>
  </li>
  <li>
    <p>The scores are public, and is semi-anonymised. From this dataset, I will:</p>
    <ol>
      <li>Identify general trends across the subjects</li>
      <li>Predict missing scores</li>
      <li>Answer whether it’s fair to give bonus scores to students in less developed areas</li>
    </ol>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="kn">import</span> <span class="n">xgboost</span> <span class="k">as</span> <span class="n">xg</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span> <span class="k">as</span> <span class="n">MSE</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="nf">set_option</span><span class="p">(</span><span class="s">'display.max_rows'</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">set_theme</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s">'data/processed/yr2019.csv'</span><span class="p">)</span> <span class="c1"># main score dataset
</span><span class="n">gdp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="s">'data/processed/grdp_per_cap.csv'</span><span class="p">)</span> <span class="c1"># to find correlation between income level and academic performance
</span>
<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>candidate_ID</th>
      <th>literature</th>
      <th>mathematics</th>
      <th>fl_code</th>
      <th>foreign_language</th>
      <th>physics</th>
      <th>chemistry</th>
      <th>biology</th>
      <th>history</th>
      <th>geography</th>
      <th>civics_study</th>
      <th>province</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1000029</td>
      <td>5.00</td>
      <td>7.2</td>
      <td>N1</td>
      <td>6.8</td>
      <td>6.0</td>
      <td>4.5</td>
      <td>4.00</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Ha Noi</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1000030</td>
      <td>6.25</td>
      <td>6.2</td>
      <td>N1</td>
      <td>8.0</td>
      <td>5.0</td>
      <td>4.5</td>
      <td>3.75</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Ha Noi</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1000031</td>
      <td>5.75</td>
      <td>6.8</td>
      <td>N1</td>
      <td>7.2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.25</td>
      <td>5.5</td>
      <td>7.0</td>
      <td>Ha Noi</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1000032</td>
      <td>4.50</td>
      <td>5.8</td>
      <td>N1</td>
      <td>9.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>7.00</td>
      <td>6.5</td>
      <td>7.0</td>
      <td>Ha Noi</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1000033</td>
      <td>5.50</td>
      <td>7.0</td>
      <td>N1</td>
      <td>3.6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.25</td>
      <td>7.5</td>
      <td>8.5</td>
      <td>Ha Noi</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">subjects</span> <span class="o">=</span> <span class="p">[</span>
 <span class="s">'literature'</span><span class="p">,</span>
 <span class="s">'mathematics'</span><span class="p">,</span>
 <span class="s">'foreign_language'</span><span class="p">,</span>
 
 <span class="s">'physics'</span><span class="p">,</span>
 <span class="s">'chemistry'</span><span class="p">,</span>
 <span class="s">'biology'</span><span class="p">,</span>
 
 <span class="s">'history'</span><span class="p">,</span>
 <span class="s">'geography'</span><span class="p">,</span>
 <span class="s">'civics_study'</span><span class="p">,]</span>
</code></pre></div></div>

<h2 id="1-overview-of-subjects-and-scores">1. Overview of subjects and scores</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_long</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">melt</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span>
    <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s">'candidate_ID'</span><span class="p">,</span> <span class="s">'province'</span><span class="p">],</span>
    <span class="n">value_vars</span><span class="o">=</span><span class="n">subjects</span><span class="p">,</span>
    <span class="n">var_name</span><span class="o">=</span><span class="s">'subject'</span><span class="p">,</span>
    <span class="n">value_name</span><span class="o">=</span><span class="s">'score'</span>
<span class="p">).</span><span class="nf">dropna</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_long</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>candidate_ID</th>
      <th>province</th>
      <th>subject</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1000029</td>
      <td>Ha Noi</td>
      <td>literature</td>
      <td>5.00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1000030</td>
      <td>Ha Noi</td>
      <td>literature</td>
      <td>6.25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1000031</td>
      <td>Ha Noi</td>
      <td>literature</td>
      <td>5.75</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1000032</td>
      <td>Ha Noi</td>
      <td>literature</td>
      <td>4.50</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1000033</td>
      <td>Ha Noi</td>
      <td>literature</td>
      <td>5.50</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig1</span><span class="p">,</span> <span class="n">axes1</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># count of students
</span><span class="n">subject_count</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">subjects</span><span class="p">].</span><span class="nf">notnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">barplot</span><span class="p">(</span>
   <span class="n">x</span><span class="o">=</span><span class="n">subject_count</span><span class="p">.</span><span class="n">values</span><span class="p">,</span>
   <span class="n">y</span><span class="o">=</span><span class="n">subject_count</span><span class="p">.</span><span class="n">index</span><span class="p">,</span>
   <span class="n">palette</span><span class="o">=</span><span class="s">"vlag"</span><span class="p">,</span>
   <span class="n">ax</span><span class="o">=</span><span class="n">axes1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="p">)</span>

<span class="c1"># distribution of scores per subject
</span><span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">df_long</span><span class="p">[</span><span class="s">'score'</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">df_long</span><span class="p">[</span><span class="s">'subject'</span><span class="p">],</span>
    <span class="n">showfliers</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">palette</span><span class="o">=</span><span class="s">"vlag"</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">axes1</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">showmeans</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">meanprops</span><span class="o">=</span><span class="p">{</span><span class="s">"marker"</span><span class="p">:</span><span class="s">"o"</span><span class="p">,</span>
                       <span class="s">"markerfacecolor"</span><span class="p">:</span><span class="s">"white"</span><span class="p">,</span> 
                       <span class="s">"markeredgecolor"</span><span class="p">:</span><span class="s">"black"</span><span class="p">,</span>
                      <span class="s">"markersize"</span><span class="p">:</span><span class="s">"8"</span><span class="p">})</span>
                      
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes1</span><span class="p">:</span>
    <span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">subjects</span><span class="p">)):</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">val</span> <span class="o">+</span> <span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'grey'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">)</span>

<span class="n">axes1</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'Number of students signing up for each subject'</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">"bold"</span><span class="p">)</span>
<span class="n">axes1</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s">'Number of students'</span><span class="p">)</span>
<span class="n">axes1</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'Distribution of scores obtained</span><span class="se">\n</span><span class="s">Circles show averages'</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">"bold"</span><span class="p">)</span>
<span class="n">axes1</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
<span class="n">axes1</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s">'Score out of 10'</span><span class="p">)</span>

<span class="n">fig1</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/vn-highschool-exam/2_analyze_7_0.png" alt="png" /></p>

<p>Subject choices:</p>

<ul>
  <li>The compulsory subjects are Maths and Literature, and for most students, a Foreign Language. Among these subjects, students struggle the most with Foreign Language where the median student scored less than half of total points.</li>
  <li>The Natural Science subjects (Physics, Chemistry, Biology) are less popular than Social Sciences (History, Geography, Civics Study)</li>
</ul>

<p>Scores:</p>
<ul>
  <li>Maths scores spread out the most. This does a good job of ranking students. Furthermore, Maths’ means and median are very close. Nice!</li>
  <li>Civics study has the highest average score. On one hand, it’s hard to ask difficult questions on this subject as it mostly concern with how one can be a ‘good’ citizen. On the other hand, it might not be a good subject to evaluate students. I would recommend a simple Pass/Fail score for this subject.</li>
</ul>

<h2 id="2-finding-correlation-between-subjects-and-predicting-missing-scores">2. Finding correlation between subjects and Predicting missing scores</h2>

<ul>
  <li>Generally, we can assume that a student who do well in a subject (such as Maths) might likely also do well in other (eg. Physics or Chemistry). As the skills required (logical thinking, being hardworking) are similar.</li>
  <li>
    <p>We can use this knowledge  to make predictions. For example: predict Maths scores based on other subjects.</p>
  </li>
  <li>Beyond simple predictions, we can find more subtle patterns. In extreme cases, we might even identify cheating students if their scores deviate too much from expected. However, this is a serious topic that require additional data (eg. students’ and their schools’ performance across time, etc) so we will not try to do so here based solely on a snapshot of limited data.</li>
</ul>

<h3 id="correlation-matrix">Correlation matrix</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">subjects</span><span class="p">]</span>
<span class="n">scores</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>literature</th>
      <th>mathematics</th>
      <th>foreign_language</th>
      <th>physics</th>
      <th>chemistry</th>
      <th>biology</th>
      <th>history</th>
      <th>geography</th>
      <th>civics_study</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.00</td>
      <td>7.2</td>
      <td>6.8</td>
      <td>6.0</td>
      <td>4.5</td>
      <td>4.00</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6.25</td>
      <td>6.2</td>
      <td>8.0</td>
      <td>5.0</td>
      <td>4.5</td>
      <td>3.75</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.75</td>
      <td>6.8</td>
      <td>7.2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.25</td>
      <td>5.5</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.50</td>
      <td>5.8</td>
      <td>9.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>7.00</td>
      <td>6.5</td>
      <td>7.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.50</td>
      <td>7.0</td>
      <td>3.6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.25</td>
      <td>7.5</td>
      <td>8.5</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="nf">corr</span><span class="p">()</span>
<span class="n">corr_matrix</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>literature</th>
      <th>mathematics</th>
      <th>foreign_language</th>
      <th>physics</th>
      <th>chemistry</th>
      <th>biology</th>
      <th>history</th>
      <th>geography</th>
      <th>civics_study</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>literature</th>
      <td>1.00</td>
      <td>0.48</td>
      <td>0.41</td>
      <td>0.24</td>
      <td>0.25</td>
      <td>0.27</td>
      <td>0.45</td>
      <td>0.49</td>
      <td>0.46</td>
    </tr>
    <tr>
      <th>mathematics</th>
      <td>0.48</td>
      <td>1.00</td>
      <td>0.57</td>
      <td>0.67</td>
      <td>0.62</td>
      <td>0.38</td>
      <td>0.41</td>
      <td>0.48</td>
      <td>0.44</td>
    </tr>
    <tr>
      <th>foreign_language</th>
      <td>0.41</td>
      <td>0.57</td>
      <td>1.00</td>
      <td>0.39</td>
      <td>0.19</td>
      <td>0.25</td>
      <td>0.33</td>
      <td>0.34</td>
      <td>0.32</td>
    </tr>
    <tr>
      <th>physics</th>
      <td>0.24</td>
      <td>0.67</td>
      <td>0.39</td>
      <td>1.00</td>
      <td>0.52</td>
      <td>0.20</td>
      <td>0.18</td>
      <td>0.22</td>
      <td>0.12</td>
    </tr>
    <tr>
      <th>chemistry</th>
      <td>0.25</td>
      <td>0.62</td>
      <td>0.19</td>
      <td>0.52</td>
      <td>1.00</td>
      <td>0.45</td>
      <td>0.17</td>
      <td>0.19</td>
      <td>0.10</td>
    </tr>
    <tr>
      <th>biology</th>
      <td>0.27</td>
      <td>0.38</td>
      <td>0.25</td>
      <td>0.20</td>
      <td>0.45</td>
      <td>1.00</td>
      <td>0.26</td>
      <td>0.30</td>
      <td>0.23</td>
    </tr>
    <tr>
      <th>history</th>
      <td>0.45</td>
      <td>0.41</td>
      <td>0.33</td>
      <td>0.18</td>
      <td>0.17</td>
      <td>0.26</td>
      <td>1.00</td>
      <td>0.60</td>
      <td>0.50</td>
    </tr>
    <tr>
      <th>geography</th>
      <td>0.49</td>
      <td>0.48</td>
      <td>0.34</td>
      <td>0.22</td>
      <td>0.19</td>
      <td>0.30</td>
      <td>0.60</td>
      <td>1.00</td>
      <td>0.58</td>
    </tr>
    <tr>
      <th>civics_study</th>
      <td>0.46</td>
      <td>0.44</td>
      <td>0.32</td>
      <td>0.12</td>
      <td>0.10</td>
      <td>0.23</td>
      <td>0.50</td>
      <td>0.58</td>
      <td>1.00</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># remove the top triangle of the matrix to simplify the heatmap
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">triu_indices_from</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1"># plot
</span><span class="n">fig2</span><span class="p">,</span> <span class="n">axes2</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span>
    <span class="n">corr_matrix</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
    <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">(</span><span class="s">"vlag_r"</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">axes2</span>
    <span class="p">)</span>

<span class="n">axes2</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'Score correlation between subjects:</span><span class="se">\n</span><span class="s">High correlations among Maths-Physics-Chemistry scores'</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">"bold"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.0, 1.0, 'Score correlation between subjects:\nHigh correlations among Maths-Physics-Chemistry scores')
</code></pre></div></div>

<p><img src="/assets/images/posts/vn-highschool-exam/2_analyze_13_1.png" alt="png" /></p>

<h3 id="predicting-math-score-based-on-other-subjects">Predicting Math score based on other subjects</h3>

<p>We will use xgboost regression as it works well with tabular data</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores_nonnull</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s">'mathematics'</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">scores_nonnull</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="s">'mathematics'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">scores_nonnull</span><span class="p">[</span><span class="s">'mathematics'</span><span class="p">]</span>


<span class="c1"># Splitting
</span><span class="n">train_X</span><span class="p">,</span> <span class="n">test_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">123</span><span class="p">)</span>
  

<span class="c1"># Instantiation
</span><span class="n">xgb_r</span> <span class="o">=</span> <span class="n">xg</span><span class="p">.</span><span class="nc">XGBRegressor</span><span class="p">(</span><span class="n">objective</span> <span class="o">=</span><span class="s">'reg:squarederror'</span><span class="p">,</span> <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">123</span><span class="p">)</span>
  

<span class="c1"># Fitting the model
</span><span class="n">xgb_r</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

 
<span class="c1"># Predict the model
</span><span class="n">pred</span> <span class="o">=</span> <span class="n">xgb_r</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>

<span class="c1"># RMSE Computation
</span><span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nc">MSE</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'RMSE : </span><span class="si">{</span><span class="n">rmse</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RMSE : 0.998
</code></pre></div></div>

<p>Using the fitted model, we can predict Math scores for those who didn’t take the test.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># predicting scores of students who dropped maths
</span><span class="n">missed_maths</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'mathematics'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">()][</span><span class="n">subjects</span><span class="p">].</span><span class="nf">drop</span><span class="p">([</span><span class="s">'mathematics'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">missed_maths_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="s">'predicted'</span><span class="p">:</span> <span class="n">xgb_r</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">missed_maths</span><span class="p">)})</span>

<span class="n">missed_maths_pred</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>predicted</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.494553</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.275107</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.323812</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.175710</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.715799</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">actual_mean</span> <span class="o">=</span> <span class="n">scores_nonnull</span><span class="p">[</span><span class="s">'mathematics'</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">dropped_mean</span> <span class="o">=</span> <span class="n">missed_maths_pred</span><span class="p">[</span><span class="s">'predicted'</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig3</span><span class="p">,</span> <span class="n">axes3</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span>
   <span class="n">data</span><span class="o">=</span><span class="n">missed_maths_pred</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">"predicted"</span><span class="p">,</span>
   <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
   <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
   <span class="n">label</span><span class="o">=</span><span class="s">'predicted scores for</span><span class="se">\n</span><span class="s">students who dropped maths'</span><span class="p">,</span>
   <span class="n">ax</span><span class="o">=</span><span class="n">axes3</span>
<span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">kdeplot</span><span class="p">(</span>
   <span class="n">x</span><span class="o">=</span><span class="n">scores_nonnull</span><span class="p">[</span><span class="s">'mathematics'</span><span class="p">],</span>
   <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
   <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
   <span class="n">label</span><span class="o">=</span><span class="s">'actual scores'</span><span class="p">,</span>
   <span class="n">ax</span><span class="o">=</span><span class="n">axes3</span>
<span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes3</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">axes3</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'Students who dropped Maths are predicted to score lower</span><span class="se">\n</span><span class="s"> than those who took the test. Most notably some having scores &lt;=1'</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">"bold"</span><span class="p">)</span>
<span class="n">axes3</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s">'Score'</span><span class="p">)</span>

<span class="n">axes3</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">dropped_mean</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">().</span><span class="nf">as_hex</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes3</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">dropped_mean</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s">'right'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s">'dropped out avg: </span><span class="si">{</span><span class="n">dropped_mean</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> '</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">().</span><span class="nf">as_hex</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes3</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">actual_mean</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">'--'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">().</span><span class="nf">as_hex</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes3</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">actual_mean</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="sa">f</span><span class="s">' actual avg: </span><span class="si">{</span><span class="n">actual_mean</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> '</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="p">.</span><span class="nf">color_palette</span><span class="p">().</span><span class="nf">as_hex</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes3</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="p">.</span><span class="mi">45</span><span class="p">)</span>

<span class="n">axes3</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'center left'</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.legend.Legend at 0x17fb30ee0&gt;
</code></pre></div></div>

<p><img src="/assets/images/posts/vn-highschool-exam/2_analyze_20_1.png" alt="png" /></p>

<h2 id="3-is-it-fair-to-give-bonus-points-for-less-developed-regions">3. Is it fair to give bonus points for less developed regions?</h2>

<ul>
  <li>Students from less developed regions are given bonus scores. Reason is that they can devote less time to study compare to their peers in wealthier regions. A bonus score gives them with better opportunity for a good univerity education and improve their prospects.</li>
  <li>This practice is only fair if students from poorer areas indeed perform worse.</li>
  <li>We can validate this by comparing score distributions between 2 regions (similar to an A/B test). In this example I compare between Ha Noi (~5,000 USD per cap) and Nghe An (~1,500 USD per cap)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># avg score per province
</span><span class="n">prov</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">pivot_table</span><span class="p">(</span>
    <span class="n">index</span><span class="o">=</span><span class="s">'province'</span><span class="p">,</span>
    <span class="n">values</span><span class="o">=</span><span class="n">subjects</span><span class="p">,</span>
    <span class="n">aggfunc</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span>
<span class="p">).</span><span class="nf">reset_index</span><span class="p">()</span>

<span class="n">prov</span> <span class="o">=</span> <span class="n">prov</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">gdp</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="s">'province'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="s">'provinces'</span><span class="p">)</span>
<span class="n">prov</span><span class="p">.</span><span class="nf">head</span><span class="p">().</span><span class="nf">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>province</th>
      <th>biology</th>
      <th>chemistry</th>
      <th>civics_study</th>
      <th>foreign_language</th>
      <th>geography</th>
      <th>history</th>
      <th>literature</th>
      <th>mathematics</th>
      <th>physics</th>
      <th>provinces</th>
      <th>grdp (million usd)</th>
      <th>population</th>
      <th>grdp/cap</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>An Giang</td>
      <td>5.08</td>
      <td>5.49</td>
      <td>7.92</td>
      <td>4.71</td>
      <td>6.44</td>
      <td>4.84</td>
      <td>5.92</td>
      <td>5.89</td>
      <td>5.63</td>
      <td>An Giang</td>
      <td>3226.8</td>
      <td>1908352</td>
      <td>1690.88</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Ba Ria Vung Tau</td>
      <td>4.60</td>
      <td>5.34</td>
      <td>7.66</td>
      <td>5.11</td>
      <td>6.05</td>
      <td>4.30</td>
      <td>5.34</td>
      <td>6.11</td>
      <td>5.66</td>
      <td>Ba Ria Vung Tau</td>
      <td>6496.1</td>
      <td>1148313</td>
      <td>5657.08</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Bac Giang</td>
      <td>4.84</td>
      <td>5.62</td>
      <td>7.57</td>
      <td>4.07</td>
      <td>6.17</td>
      <td>4.43</td>
      <td>5.53</td>
      <td>5.45</td>
      <td>5.88</td>
      <td>Bac Giang</td>
      <td>3772.7</td>
      <td>1803950</td>
      <td>2091.36</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Bac Kan</td>
      <td>4.92</td>
      <td>5.22</td>
      <td>7.52</td>
      <td>3.70</td>
      <td>6.10</td>
      <td>4.54</td>
      <td>5.24</td>
      <td>4.39</td>
      <td>5.17</td>
      <td>Bac Kan</td>
      <td>427.2</td>
      <td>313905</td>
      <td>1360.92</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bac Lieu</td>
      <td>5.22</td>
      <td>5.48</td>
      <td>7.86</td>
      <td>4.33</td>
      <td>6.33</td>
      <td>4.77</td>
      <td>6.02</td>
      <td>5.86</td>
      <td>5.63</td>
      <td>Bac Lieu</td>
      <td>1638.2</td>
      <td>907236</td>
      <td>1805.70</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig4</span><span class="p">,</span> <span class="n">axes4</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">scatterplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">prov</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s">'grdp/cap'</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s">'mathematics'</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="s">'population'</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s">'#3c76aa'</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">75</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">axes4</span>
<span class="p">)</span>

<span class="n">axes4</span><span class="p">.</span><span class="nf">axvspan</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2500</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'#fcba03'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">25</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s">'None'</span><span class="p">)</span>


<span class="n">axes4</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'Strong positive correlation between GDP per cap and Maths score</span><span class="se">\n</span><span class="s">up until 2,500 USD/person level'</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s">'left'</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">"bold"</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes4</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/vn-highschool-exam/2_analyze_23_0.png" alt="png" /></p>

<ul>
  <li>From 0 to around 2,500 USD/cap, we see a very strong positive relation between GRDP and Maths score. But above 2,500 USD/cap the trend is flattende.</li>
  <li>This implies that after a certain standard of living is achived, score is less impacted by wealth. At this point, basic education costs (books/tuitions) are covered. And other factors impact more.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Ha Noi avg Maths: </span><span class="si">{</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s">'province'</span><span class="p">]</span><span class="o">==</span><span class="s">'Ha Noi'</span><span class="p">)][</span><span class="s">'mathematics'</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Nghe An avg Maths: </span><span class="si">{</span><span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s">'province'</span><span class="p">]</span><span class="o">==</span><span class="s">'Nghe An'</span><span class="p">)][</span><span class="s">'mathematics'</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ha Noi avg Maths: 6.03
Nghe An avg Maths: 5.41
</code></pre></div></div>

<p>Hypothesis testing of 2 population means</p>

<ul>
  <li>Null hypothesis: 2 provinces have identical averages</li>
  <li>Alternative hypothesis: 2 provinces have different averages</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hanoi_math</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s">'province'</span><span class="p">]</span><span class="o">==</span><span class="s">'Ha Noi'</span><span class="p">)][</span><span class="s">'mathematics'</span><span class="p">].</span><span class="nf">dropna</span><span class="p">()</span>
<span class="n">nghean_math</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s">'province'</span><span class="p">]</span><span class="o">==</span><span class="s">'Nghe An'</span><span class="p">)][</span><span class="s">'mathematics'</span><span class="p">].</span><span class="nf">dropna</span><span class="p">()</span>

<span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span>
    <span class="n">a</span><span class="o">=</span><span class="n">hanoi_math</span><span class="p">,</span>
    <span class="n">b</span><span class="o">=</span><span class="n">nghean_math</span><span class="p">,</span>
    <span class="n">alternative</span><span class="o">=</span><span class="s">'greater'</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ttest_indResult(statistic=50.43617963341244, pvalue=0.0)
</code></pre></div></div>

<p>Since p-value &lt; 0.05, we reject the null hypothesis. Our sample data favor that students in Ha Noi indeed perform better than Nghe An.</p>

<p>At the moment, it still make sense to support students from less developed regions. However, as shown in the chart, upon reaching certain GRDP level, students’ scores stop improving. Therefore, in order to ensure fairness, it will require policymaker to monitor the pace of development and make adjustments accordingly.</p>

<h2 id="references">References</h2>

<ol>
  <li>Bonus scores based on region. https://huongnghiep.hocmai.vn/diem-uu-tien-la-gi-tat-tan-tat-ve-cach-tinh-diem-uu-tien-xet-tuyen-dai-hoc/</li>
</ol>]]></content><author><name>Vo Duy Do</name></author><category term="analysis" /><category term="visualization" /><summary type="html"><![CDATA[Analyzing Vietnam High School graduation exam scores. Identifying trends, predicting missing scores and determining whether it's fair to give bonus score based on geographical regions]]></summary></entry><entry><title type="html">Simulating a queue system</title><link href="https://dobeok.github.io//jekyll-theme-yat/2022/09/29/sim-queue.html" rel="alternate" type="text/html" title="Simulating a queue system" /><published>2022-09-29T05:00:00+00:00</published><updated>2022-09-29T05:00:00+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2022/09/29/sim-queue</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2022/09/29/sim-queue.html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>In this post I will use <a href="https://simpy.readthedocs.io/en/latest/">simpy</a> to simulate a queueing line at the airport check in counters. This is an example of Discret-event simulation (DES). In contrast to Monte-Carlo simulation, DES are useful when you need to keep track of a system’s state and analyze resource usage over time.</p>

<p>There are many practial use cases where you might need DES. In particular, for a queue system, we want to balance out cost (as reflected by number of counters) vs. customer experience (as measured by wait time)</p>

<p align="center">
  <img alt="changi airport" src="/assets/images/posts/simulate-queue/airport.jpeg" />
    <em>Picture I took at Changi Airport before going on a vacation</em>
</p>

<h2 id="assumptions--methodology">Assumptions &amp; Methodology</h2>

<p><img src="/assets/images/posts/simulate-queue/queue diagram.png" alt="queue diagram" /></p>

<ul>
  <li>There are 8 counters available for check-in. When passengers arrive that the airport terminal, they will join a shared queue and go up to the next available counter.</li>
  <li>Check-in time follows a normal distribution with a mean of 2 minutes and standard deviation of 1 minute. To spice things up, I’ve also added a 5% chance that a passenger might have issues with their paperwork and can take up to 10 minutes to resolve.</li>
  <li>Before the counter opens, a group of 30 passengers arrived at the airport. (They just want to have more buffer time and enjoy walking around the airport)</li>
  <li>In the first 30 minutes, passengers arrive at a slower rate. Afterwards, the arrival rate increases.</li>
</ul>

<p>The above assumptions are coded as following:</p>
<pre><code class="language-python3">NUM_COUNTERS = 8

CHECK_DURATION_AVG = 2
CHECK_DURATION_STD = 1

PASSENGER_INTERVAL_1ST = 1 # on average, 1 customer arrived every minute
PASSENGER_INTERVAL_2ND = .33 # on average, 3 customers arrived every minute

INITIAL_NUM_PASSENGERS = 30
MAX_PASSENGERS = 250
</code></pre>
<p>Note: In simpy, time units can be arbitrary depending on the problem you are modeling. For the sake of clarify, I will use minutes to measure time in this model.</p>

<p>The full code can be found at the end of the post. Here I’d like to highlight a few key details:</p>

<h3 id="modeling-the-check-in-process">Modeling the check in process</h3>

<pre><code class="language-python3">def check_in(self, passenger):

    p = np.random.uniform(low=0.0, high=1.0)

    # normal passengers
    if p &lt; .95:
        random_time = max(1, np.random.normal(self.check_duration, self.check_std))
    
    # 5% of passengers have problems and need more time
    else:
        random_time = max(10, np.random.normal(self.check_duration, self.check_std))

    print(f'Start checking in passenger {passenger} at {self.env.now:1f}')
    yield self.env.timeout(random_time)
    print(f'Finish checking in passenger {passenger} at {self.env.now:1f}')
</code></pre>

<p>Here we’re doing 2 things:</p>

<pre><code class="language-python3">p = np.random.uniform(low=0.0, high=1.0)
if p &lt; .95:
    ...
</code></pre>

<p>We get a random number, if the value is &lt; .95, then the passenger’s check in time follows the distribution with CHECK_DURATION_AVG and CHECK_DURATION_STD.
For the remaining 5% of the cases, the staff will need 10 minutes to complete.</p>

<pre><code class="language-python3">print(f'Start checking in passenger {passenger} at {self.env.now:1f}')
yield self.env.timeout(random_time)
print(f'Finish checking in passenger {passenger} at {self.env.now:1f}')
</code></pre>
<p>This is the actual check-in event. The 2 printing functions are optional, but helpful to collect the output to analyze the system. The env.timeout() method simulates check-in duration.</p>

<h3 id="modeling-passengers-behavior">Modeling passengers behavior</h3>

<pre><code class="language-python3">def passenger(env, pid, ch_in):
    """
    pid = unique identifier for passenger
    """
    print(f'Passenger {pid} arrived at the airport and join the queue at {env.now:.1f}')

    # join queue and wait for the next available counter
    with ch_in.staff.request() as request:
        yield request
        yield env.process(ch_in.check_in(pid))
</code></pre>

<p>This is the passenger process. Each passenger is assigned a unique id (<code class="language-plaintext highlighter-rouge">pid</code>) for ease of tracking.</p>

<pre><code class="language-python3">with ch_in.staff.request() as request:
    yield request
    yield env.process(ch_in.check_in(pid))
</code></pre>
<p>This part simulates the passenger joining the queue, and will be served when they’re at the front of the queue and there’s an available counter.</p>

<h3 id="setting-up-the-simulation">Setting up the simulation</h3>

<pre><code class="language-python3">def setup(env, initial_passengers, passenger_interval_1st, passenger_interval_2nd, max_passengers):
    # initialize first of group passengers who arrived before counter open
    for i in range(initial_passengers):
        env.process(passenger(env, i, ch_in))
    

    # simulate passengers coming in with normal interarrival time
    while i &lt;= max_passengers:
        # first hour
        if env.now &lt; 30:
            t = np.random.exponential(passenger_interval_1st)

        else:
            t = np.random.exponential(passenger_interval_2nd)
        
        yield env.timeout(t)
        
        i += 1
        env.process(passenger(env, i, ch_in))
</code></pre>

<p>Normally, we don’t run the simulation just once and take the first result! But instead we will repeat it for ten or hundred of thousand times and perhaps changing the assumptions/parameters. Hence it’s convenient to write a setup function to initialize the simulation.</p>

<p>The rest of the codes are standard python functions. You can add additional logging features to help debug or customize queue logic.</p>

<h2 id="results--observations">Results &amp; Observations</h2>

<h3 id="passengers-arrival">Passengers arrival</h3>

<p align="center">
  <img alt="fig1" src="/assets/images/posts/simulate-queue/fig1-212454.png" />
    <em>Fig 1 (top), Fig 2 (bottom)</em>
</p>

<p>Figures 1 and 2 shows details for individual passengers.</p>
<ul>
  <li>Figure 1 shows the cumulative number of passengers arriving against time
    <ul>
      <li>At time 0, we had 30 passengers before the counters opended. The line starts at point (0, 30).</li>
      <li>The slope is flatter before the 30 minutes mark, and got stepper afterwards. This is because we assumed higher arrival rate.</li>
    </ul>
  </li>
  <li>Figure 2 shows the time each passenger spent in the queue system: from arriving at the terminal until they finished checking in
    <ul>
      <li>Each passenger is one horizontal line. The blue dots indicate start time, orange dots indicate end time.</li>
      <li>The length of the line is proportional to the time taken.</li>
      <li>The longer lines that stand out incidate passengers with issues and held their counter up for 10 minutes ;(</li>
    </ul>
  </li>
  <li>Additional details for wait time</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center"> </th>
      <th style="text-align: center">service_time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">count</td>
      <td style="text-align: center">250</td>
    </tr>
    <tr>
      <td style="text-align: center">mean</td>
      <td style="text-align: center">2.55555</td>
    </tr>
    <tr>
      <td style="text-align: center">std</td>
      <td style="text-align: center">2.00238</td>
    </tr>
    <tr>
      <td style="text-align: center">min</td>
      <td style="text-align: center">1</td>
    </tr>
    <tr>
      <td style="text-align: center">25%</td>
      <td style="text-align: center">1.4025</td>
    </tr>
    <tr>
      <td style="text-align: center">50%</td>
      <td style="text-align: center">2.07835</td>
    </tr>
    <tr>
      <td style="text-align: center">75%</td>
      <td style="text-align: center">2.91865</td>
    </tr>
    <tr>
      <td style="text-align: center">max</td>
      <td style="text-align: center">10</td>
    </tr>
  </tbody>
</table>

<h3 id="queue-and-utilization">Queue and Utilization</h3>

<p align="center">
  <img alt="fig2" src="/assets/images/posts/simulate-queue/fig2-212454.png" />
    <em>Fig 3 (top), Fig 4 (bottom)</em>
</p>

<p>Figure 3 and 4 monitor queue length and resource utilizations.</p>
<ul>
  <li>In Figure 3, we can see the queue line is the longest at the beginning
    <ul>
      <li>This is due to the group of early passengers. Therefore, if you don’t want to wait in line, it’s probably best to avoid arriving too early!</li>
      <li>The queue starts to build up again as passengers arrived at an increased rate after 30 mins.</li>
    </ul>
  </li>
  <li>Finally we are also interested in resource utilizations. This is where the trade-off comes in.
    <ul>
      <li>Utilization at any time is measured as the number of busy counter / total number of counters</li>
      <li>We can estimate overall utilization by measuring area under the curve. In this case it’s equal to roughly 81%</li>
      <li>As a business owner, we wouldn’t want our resources to stay idle for too long. Perhaps we might try to reduce the number of counter by 1 and re-run the simulation. However, it’s important to note that for an airport, all passengers need to be checked-in before flight time. Hence maximum utilization might not be the highest priority.</li>
    </ul>
  </li>
</ul>

<h2 id="takeaway">Takeaway</h2>

<ul>
  <li>This is only a toy sample with somewhat simple assumptions. We can observe real data and model the different processes (arrival time, check-in time, etc) more accurately. However, even with such simple assumptions, we can see that DES is an useful tool for analyzing systems and finding bottlenecks.</li>
  <li>For our airport queue model, we only take number of counters as cost. However, in another business scenario (such as a restaurant queue), costs might also include lost income from reneged customer (who might wait too long).</li>
  <li>Simpy is flexible and not just limited to modelling queueing. Other use cases might be allocating production capacity at a manufacturing plant, or perhaps scheduling transportation trucks between warehouses. All these real life scenarios inherently contains a lot of random variations and would benefit from DES.</li>
</ul>

<h2 id="full-code">Full code</h2>]]></content><author><name>Vo Duy Do</name></author><category term="simulation" /><category term="visualization" /><summary type="html"><![CDATA[Using simpy to simulate a queueing line at the airport check in counters. This is an example of Discret-event simulation (DES). In contrast to Monte-Carlo simulation, DES are useful when you need to keep track of a system’s state and analyze resource usage over time]]></summary></entry><entry><title type="html">Finding the most similar questions on r/AskReddit</title><link href="https://dobeok.github.io//jekyll-theme-yat/2022/09/25/askreddit-topic-similarity.html" rel="alternate" type="text/html" title="Finding the most similar questions on r/AskReddit" /><published>2022-09-25T05:00:00+00:00</published><updated>2022-09-25T05:00:00+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2022/09/25/askreddit-topic-similarity</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2022/09/25/askreddit-topic-similarity.html"><![CDATA[<h3 id="introduction">Introduction</h3>

<p>In <a href="https://www.reddit.com/r/AskReddit/">r/AskReddit</a>, users can submit open-ended questions to which other users can then reply with answers. The subreddit describes its focus as “to ask and answer questions that elicit thought-provoking discussions”. It has been one of the most popular subreddits on Reddit.</p>

<p>In this post, I will analyze the top 1,000 questions from r/askreddit and threads that are most similar to each other. This technique can be used for a few purposes:</p>
<ol>
  <li>Recommend similar questions to the one that a user is reading in order to increase user engagement</li>
  <li>Identify reposted questions, which is undesirable user experience for readers</li>
  <li>Outside of forums, this can also be used in news site. Publishers can show relevant news pieces about a particular topic that the user is reading</li>
</ol>

<p align="center">
  <img alt="img-name" src="/assets/images/posts/askreddit-similar/askreddit.jpg" />
    <em>Top posts of the year</em>
</p>

<h3 id="methodology">Methodology</h3>

<p>I fetched <a href="https://github.com/dobeok/askreddit-topic-similarity/blob/b046dc6c9cb1274337f6c38b6c7033bb345303d4/data/1000posts.txt">1,000</a> highest rated questions in the month. These rankings are based on users upvotes.</p>

<iframe frameborder="0" style="min-width: 200px; width: 100%; height: 460px;" scrolling="no" seamless="seamless" srcdoc="&lt;html&gt;&lt;body&gt;&lt;style type=&quot;text/css&quot;&gt;.gist .gist-data { height: 350px; }&lt;/style&gt;&lt;script src=&quot;https://gist.github.com/dobeok/35f28b7d3fe7062692f055653306e1f4.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;"></iframe>

<p><strong>Step-by-step data processing</strong></p>

<ol>
  <li>Remove english stop words. Common words such as ‘the’, ‘and’, ‘I’ appear frequently but by themselves don’t convey insight into the topic of the question. We want to remove them so that they won’t inflate our similarity scores.</li>
  <li>Stem words using nltk (removing plurals, stemming verbs in different tenses, etc).</li>
  <li>Convert raw text string to vector using bag-of-word method, using term frequency - inverse document frequency (TF-IDF) method.</li>
  <li>Use cosine similarity metric to find the closest matching thread name.
    <ul>
      <li>Similarity score ranges from 0 to 1 with 1 being an exact match.</li>
      <li>Note that due to our preprocessing above, questions that are originally slightly different may still have a score of 1</li>
      <li>The dimension of the output is a 1,000 x 1,000 dataframe where each row and each column represent a question. For each row, our goal is to find the column index containing the highest score. Note that, in the main diagonal, values will always be 1 because it’s the row and column are representing the same question. To prevent this, we will set the main diagonal of the matrix to 0 using <code class="language-plaintext highlighter-rouge">np.fill_diagonal</code></li>
    </ul>
  </li>
</ol>

<h3 id="results-and-observations">Results and Observations</h3>
<ul>
  <li>Thread names are usually short. Therefore using raw word count will yield higher similarity score than tf-idf because of common phrases that are not filted as stop words (eg. what, you(r), etc.)</li>
  <li>tf-idf works slightly better because rarer topics can be matched</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">original thread name</th>
      <th style="text-align: left">best match</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">What would you do if you woke up in the 80’s?</td>
      <td style="text-align: left">What’s your favorite 80’s movie?</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">What is your strange turn-on?</td>
      <td style="text-align: left">what’s the weirdest thing that’s turned you on?</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">What’s worse than a wet handshake?</td>
      <td style="text-align: left">What is 100% worse when wet?</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">Zoo workers of reddit, what is the dumbest thing someone has asked about an animal?</td>
      <td style="text-align: left">What’s the dumbest thing you believed as a child?</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">What is your favorite bromance in fiction?</td>
      <td style="text-align: left">Who is your favorite fictional doctor?</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">Women of reddit, whats the stupidest excuse a man has ever given you to not wear a condom?</td>
      <td style="text-align: left">Women of reddit, what is the grossest thing a man has said to you?</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">The world is now under the iron fist of Canada. What changes?</td>
      <td style="text-align: left">What is the most disturbing fact you know about Canada?</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">what’s a song that everybody knows?</td>
      <td style="text-align: left">What do you hate that everybody seems to love?</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">When it comes to dating apps, what is an automatic “pass” for you?</td>
      <td style="text-align: left">WWhat must one never do on a first date?</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: left">Who’s someone you looked up to or idolized as a kid that you now can’t stand?</td>
      <td style="text-align: left">Who is a famous singer that you cannot stand their singing voice?</td>
    </tr>
  </tbody>
</table>

<h3 id="takeaways">Takeaways</h3>

<p align="center">
  <img alt="img-name" src="/assets/images/posts/askreddit-similar/posts-per-day.png" />
    <em>Number of daily posts on r/AskReddit, retrieved on 10 Sep 2022. <a href="https://subredditstats.com/r/askreddit">Source: subredditstats.com</a></em>
</p>

<ul>
  <li>In this post I only compared data from a group of 1,000 posts, which is not a big number compared to the averaged more than 6,000 posts <strong>per day</strong>. This is a limit from PRAW. I can potentially look for alternative sources that archive reddit posts and do an offline analysis (for exammple: monthly data). With more data points, the matching process will most likely improve.</li>
  <li>Some of the matches found are not strictly accurate (potentially due to lacking of similar questions), but interesting. As a owner, I think this algo strike a good balance between producing good enough results and being simple to implement.</li>
</ul>

<h3 id="the-full-code">The full code</h3>

<pre><code class="language-python3">from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.stem.snowball import SnowballStemmer

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

plt.style.use('fivethirtyeight')
pd.set_option('display.max_colwidth', 500)

np.random.seed(9) # to fix sampled data


orig_corpus = []
with open('data/1000posts.txt') as file:
    for line in file:
        orig_corpus.append(line.replace('\n', ''))


stemmer = SnowballStemmer('english')


def stem_tokens(text):
    text = text.strip()
    words = text.lower().split()
    words = [stemmer.stem(word) for word in words]
    return ' '.join(words)


corpus = [stem_tokens(_) for _ in orig_corpus]

# thread1: orignal list of thread name
# sim-tf: closest match, using term frequency
# sim-tf-idf: closest mathh, using term frequency - inverse document frequency
df = pd.DataFrame({
    'orig_thread': orig_corpus,
    'stemmed_thread': corpus})
df.head()


# using raw count
count_vectorizer = CountVectorizer(stop_words='english', min_df=0.005)
X_count = count_vectorizer.fit_transform(corpus)

# most frequent words
word_freq = pd.DataFrame({
    'word': count_vectorizer.get_feature_names_out(),
    'freq': X_count.toarray().sum(axis=0)
})
word_freq_15 = word_freq.sort_values(by='freq', ascending=False).head(15)

# plot
fig, ax = plt.subplots(figsize=(12, 3))
ax.bar(
    x=word_freq_15['word'].values,
    height=word_freq_15['freq'].values,
    width=1,
    ec='white'
)
ax.set_title('Top 15 words by count')
fig.savefig('./assets/top_15.png', bbox_inches='tight')



df_count = pd.DataFrame(X_count.toarray(), columns=count_vectorizer.get_feature_names_out())
df_count_sim = pd.DataFrame(cosine_similarity(df_count, dense_output=True))
df_count_sim_as_np = df_count_sim.values

np.fill_diagonal(df_count_sim_as_np, 0)
df_count_result = pd.DataFrame(df_count_sim_as_np)
df_count_result['best_match (count)'] = df_count_result.idxmax()
df_count_result['similarity (count)'] = df_count_result.max()

count_result = df_count_result[['best_match (count)', 'similarity (count)']]
df = df.merge(count_result, how='left', left_index=True, right_index=True)




# using tf-idf
tfidf_vectorizer = TfidfVectorizer(stop_words='english')
X_tfidf = tfidf_vectorizer.fit_transform(corpus)
df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

df_tfidf_sim = pd.DataFrame(cosine_similarity(df_tfidf, dense_output=True))
df_tfidf_sim_as_np = df_tfidf_sim.values

np.fill_diagonal(df_tfidf_sim_as_np, 0)
df_tfidf_result = pd.DataFrame(df_tfidf_sim_as_np)
df_tfidf_result['best_match (tf-idf)'] = df_tfidf_result.idxmax()
df_tfidf_result['similarity (tf-idf)'] = df_tfidf_result.max()

tfidf_result = df_tfidf_result[['best_match (tf-idf)', 'similarity (tf-idf)']]
df = df.merge(tfidf_result, how='left', left_index=True, right_index=True)

df['best_match (count)'] = df['best_match (count)'].map(df['orig_thread'].to_dict())
df['best_match (tf-idf)'] = df['best_match (tf-idf)'].map(df['orig_thread'].to_dict())

# compare
# random 10
sample_index = np.random.randint(0, len(corpus), 10)

print(df.loc[sample_index][['orig_thread', 'best_match (count)', 'best_match (tf-idf)']].reset_index().to_markdown())


# plot
bins = [_/10 for _ in range(0, 11)]

fig, ax = plt.subplots()
ax.clear()
pd.cut(tfidf_result['similarity'], bins=bins).value_counts().sort_index().plot(ax=ax, kind='bar', width=1, ec='white', alpha=.3, color='#fb553b', label='tf-idf')
pd.cut(count_result['similarity'], bins=bins).value_counts().sort_index().plot(ax=ax, kind='bar', width=1, ec='white', alpha=.3, label='raw count')
ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=2)
fig.savefig('./assets/compare sim score.png', bbox_inches='tight')
</code></pre>

<h3 id="end">End</h3>]]></content><author><name>Vo Duy Do</name></author><category term="tf-idf" /><category term="sklearn" /><summary type="html"><![CDATA[r/AskReddit is a popular subreddit where users can submit open-ended questions. In this analysis, I analyze the top 1,000 questions and find those that are most similar. The resulting technique can be applied to recommending similar questions to increase engagement, or identifying reposted questions]]></summary></entry><entry><title type="html">Analyzing my poker games</title><link href="https://dobeok.github.io//jekyll-theme-yat/2022/08/20/pokernow.html" rel="alternate" type="text/html" title="Analyzing my poker games" /><published>2022-08-20T05:11:27+00:00</published><updated>2022-08-20T05:11:27+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2022/08/20/pokernow</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2022/08/20/pokernow.html"><![CDATA[<h3 id="introduction">Introduction</h3>

<p>During covid group gathering restrictions, my friend groups moved our board game sessions online, including poker (thanks <a href="https://www.pokernow.club/">pokernow.club</a>). The game also provided log data in csv format for each hand. I always wanted to find out what the winning players are doing differently, and hopefully improve my game.</p>

<p align="center">
  <img alt="img-name" src="/assets/images/posts/pokernow/pokernow-screenshot.jpg" />
    <em>Where I used to hang out during lockdown</em>
</p>

<h3 id="raw-data">Raw data</h3>
<p>A sample hand in the game log looks like below. The 1st column contains the log details (player names, action, value). The 2nd column contains timestamp. At first glance, there are a a lot of details. However, we will need to do some data pre-processing before we can start analyzing.</p>

<script src="https://gist.github.com/dobeok/d5006c2bf249277680e890b1fa19b8d6.js"></script>

<h3 id="is-the-game-fair">Is the game fair?</h3>

<p>Since the game’s Random Number Generator is a blackbox, we wanted to make sure that the cards dealt are fair. One way to verify this is by looking at flopped cards and plot their distributions. We can extract all flops by grepping lines containing “flop”</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="nb">ls</span>
<span class="c"># raw_data.csv</span>

<span class="o">&gt;</span> <span class="nb">grep</span> <span class="nt">-i</span> flop raw_data.csv
<span class="c"># "Flop:  [3♦, Q♠, 7♥]"...</span>
<span class="c"># "Flop: [...</span>
</code></pre></div></div>

<p>As we moved from offline to online, we were able to play a lot more hands as there’s no time need to shuffle and deal out the cards. That’s when we also started to observed patterns that didn’t exists! (eg. confirmation biases for perceived higher frequencies of certain cards combinations).</p>

<p><img src="/assets/images/posts/pokernow/flop-dist.png" alt="flop frequency" /></p>

<p>I conductde a Chi-squared goodness-of-fit test and the observed frequencies are not statistically significant. Game was fair.</p>

<p>The above method would work similarly for Turns and Rivers. The full code can be found <a href="https://github.com/dobeok/analyze-pokernow-games/blob/main/A-game-setup/analyze-flops.py">here</a></p>

<h3 id="how-did-we-play-as-a-group">How did we play as a group?</h3>

<h4 id="pot-sizes">Pot sizes</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">pot_sizes</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="s">'hand_id'</span><span class="p">)[</span><span class="s">'pot_size'</span><span class="p">].</span><span class="nf">max</span><span class="p">().</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.20</span>


<span class="n">pot_sizes</span><span class="p">.</span><span class="nf">to_frame</span><span class="p">().</span><span class="nf">hist</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ec</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'Raw pot size distribution'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s">'Number of hands'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s">'Big blinds'</span><span class="p">)</span>

<span class="n">np</span><span class="p">.</span><span class="nf">log10</span><span class="p">(</span><span class="n">pot_sizes</span><span class="p">).</span><span class="nf">to_frame</span><span class="p">().</span><span class="nf">hist</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ec</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'log(pot size) distribution'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="s">'Number of hands'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="s">'log(Big blinds)'</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="s">'Median pot size is about 10^1.5 ~ 31 x BB'</span><span class="p">)</span>

</code></pre></div></div>
<p><img src="/assets/images/posts/pokernow/img1-potsize.png" alt="" /></p>

<p>The left chart (raw pot sizes) shows that the distribution is heavily skewed. It’s easier to use log of pot size (right chart) and see that the median pot value is around 30x BB (~10**1.5)</p>

<h4 id="at-which-phases-are-the-hands-won">At which phases are the hands won?</h4>

<pre><code class="language-python3">fig, ax = plt.subplots()
ax.clear()
df.loc[df['action']=='Won'].groupby('hand_id')['phase'].max().value_counts(dropna=False, ascending=True).plot(ax=ax, kind='barh', width=1, ec='white')
ax.set_title('At which phases are hands won?')
ax.set_ylabel('Phase')
ax.set_xlabel('Number of hands')
</code></pre>

<p><img src="/assets/images/posts/pokernow/img7-phase.png" alt="" /></p>

<p>Judging from the result, we can conclude that the game was pretty casual as it often went to River. My hypothesis is that good players have better evaluation of their hands strength, hence they can make decisions earlier (eg. folding earlier). Meanwhile, at a lower stake game, player don’t lose much in terms of dollar value hence it’s ok to commit to the hand for longer.</p>

<p>We can verify this by comparing hand end phase vs. a higher stake game.</p>

<h3 id="players-behaviors">Player’s behaviors</h3>

<p>Next we analyze player’s behavior, which is the goal of the analysis. Though the raw file contains all the information we need, we it needs some processing before we can find any insights.</p>

<ol>
  <li>Player names can be matched with Regex pattern <code class="language-plaintext highlighter-rouge">" (.+) @ [A-Za-z0-9\-]"</code></li>
  <li>Possible actions are <code class="language-plaintext highlighter-rouge">posts a small/big blind</code>, <code class="language-plaintext highlighter-rouge">folds</code>, <code class="language-plaintext highlighter-rouge">calls</code>, <code class="language-plaintext highlighter-rouge">checks</code>, <code class="language-plaintext highlighter-rouge">bets</code>, <code class="language-plaintext highlighter-rouge">raises</code></li>
  <li>To identify player’s VPIP (Voluntary Put money In Pot) and PFR (Pre-flop Raises), we will need to distinguish between voluntary action (bets/raises/calls) vs non-voluntary actions (blinds/checks) which say nothing about the player’s choice.</li>
</ol>

<p>The full data prepocessing can be found in <a href="https://github.com/dobeok/analyze-pokernow-games/blob/main/B-game-play/analyze.ipynb">this notebook</a></p>

<h4 id="overview--number-of-hands-played-winnings-win-per-hand">Overview:  Number of hands played, Winnings, Win per hand</h4>

<p>By itself number of hands played only shows how many hands the players sit in. But will be useful to calculate the various playstyle metrics below.</p>

<p>We can make a reasonable assumption that, given enough hands, the better players win more. Next we will analyse different patterns of behaviors. Hopefully we can learn from the winners here.</p>

<pre><code class="language-python3"># pl = player dataframe to store all metrics
pl = df.loc[(df['phase']=='Pre-flop') &amp; (df['rank-P0']==1)]['player_name'].value_counts(dropna=False).to_frame(name='num_hands_played')
_expenses = df.groupby('player_name')['put_in'].sum()
_expenses.name = 'total_expenses'


_income = df.loc[df['action']=='Won'].groupby('player_name')['_amount'].sum().sort_values()
_income.name = 'total_income'

pl = pl.merge(_income, left_index=True, right_index=True)
pl = pl.merge(_expenses, left_index=True, right_index=True)

pl['win/hand'] = (pl['total_income'] - pl['total_expenses']) / pl['num_hands_played']

pl.sort_values(by='win/hand', ascending=False).head(5)

fig2, axes = plt.subplots(1, 3, figsize=(12, 3.5), sharey=True)
pl = pl.sort_values(by='num_hands_played')
pl15 = pl[-15:]
pl15['num_hands_played'].plot(ax=axes[0], title='Num hands played', kind='barh', width=1, ec='white')
(pl15['total_income'] - pl15['total_expenses']).plot(ax=axes[1], title='Net win (no. of BB)', kind='barh', ec='white', width=1)
pl15['win/hand'].plot(ax=axes[2], title='Win per hand (no of. BB)', kind='barh', ec='white', width=1)
axes[0].set_ylabel('player id')
</code></pre>
<p><img src="/assets/images/posts/pokernow/img4-player-overview.png" alt="" /></p>

<p>From this chart we can see that ..6efd2f is a good player. We should try to find out how he/she plays!</p>

<h4 id="vpip-voluntarily-put-in-pot--pfr-pre-flop-raises">VPIP: Voluntarily Put In Pot &amp; PFR: Pre-flop Raises</h4>

<p>VPIP tracks the percentage of hands in which a particular player voluntarily puts money into the pot preflop. VPIP increases when a player could fold but instead commits money to the pot preflop. This includes limping (merely calling the big blind), calling, and raising.</p>

<p>PFR tracks the percentage of hands in which a particular player makes a preflop raise when having the opportunity to fold or call instead. This includes reraises. By definition, PFR is a subset of VPIP. So we will plot the ratio PFR/VPIP to measure player’s tendency.</p>

<p><img src="/assets/images/posts/pokernow/img5-vpip-reg.png" alt="" /></p>

<p><img src="/assets/images/posts/pokernow/img6-pfr-reg.png" alt="" /></p>

<p>It’s clearer now that the winning players play fewer hands (lower % VPIP). But when they play, they are more aggressive with raisings!</p>

<h3 id="takeaways">Takeaways</h3>

<ul>
  <li>
    <p>Some of the results are not surprising based on common knowledge (play fewer hands, and more aggressive). However, it’s one thing to read and memorize the theory. But to see how the game plays out really convinced me to adjust my game and hopefully obtain better results.</p>
  </li>
  <li>
    <p>Since our games are casual and not meant to make money, I expect most of my friends to not stick strictly to the theoretically correct way of playing. Hence, only aggregating the data as above might not be the best method. Instead, I can also identify the biggest pots played and analyze them more closely. This will definitely contain more useful insights into each player’s playstyle.</p>
  </li>
</ul>

<h3 id="end">End</h3>]]></content><author><name>Vo Duy Do</name></author><category term="pandas" /><category term="visualization" /><summary type="html"><![CDATA[Using pandas to parse raw game logs to analyze game fairness, players trends and behaviors.]]></summary></entry><entry><title type="html">Cohort and Retention analysis</title><link href="https://dobeok.github.io//jekyll-theme-yat/2022/08/05/cohort-retention.html" rel="alternate" type="text/html" title="Cohort and Retention analysis" /><published>2022-08-05T14:00:00+00:00</published><updated>2022-08-05T14:00:00+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2022/08/05/cohort-retention</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2022/08/05/cohort-retention.html"><![CDATA[<h3 id="introduction">Introduction</h3>

<p>Cohort analysis provides insights into users behaviors by segmenting them into mutually exclusive groups and observe the differences. Though there are multiple ways to define a cohort, the most common is grouping users by acquisition date.</p>

<p>Most serious analytics software have built-in cohort analysis tools. But knowing how to create one using python can come in handy.</p>

<h3 id="creating-a-cohort-heatmap">Creating a cohort heatmap</h3>

<p>Input data is a generic sales log including 3 columns: unique customer id, order date and orders quantity</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/retention/cohort-1.png" alt="cohort-1" width="300" /></p>

<p>The most suitable time range depends on your product: the choice could be day/week/month. For an apps that you expect daily user (such as a language learning apps, daily frequency is suitable). For an e-commerce website, perhaps monthly purchases would yield the best indicator.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="s">'order_week'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'order_date'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="nf">isocalendar</span><span class="p">().</span><span class="n">week</span>
<span class="n">df</span><span class="p">[</span><span class="s">'cohort'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="s">'customer_id'</span><span class="p">)[</span><span class="s">'order_week'</span><span class="p">].</span><span class="nf">transform</span><span class="p">(</span><span class="s">'min'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'weeks_since_first_order'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'order_week'</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s">'cohort'</span><span class="p">]</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/retention/cohort-2.png" alt="cohort-2" width="600" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cohort_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">([</span><span class="s">'cohort'</span><span class="p">,</span> <span class="s">'weeks_since_first_order'</span><span class="p">])[</span><span class="s">'customer_id'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">.</span><span class="n">nunique</span><span class="p">).</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">cohort_data</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/retention/cohort-3.png" alt="cohort-3" width="300" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cohort_count</span> <span class="o">=</span> <span class="n">cohort_data</span><span class="p">.</span><span class="nf">pivot_table</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s">'cohort'</span><span class="p">,</span>
                                       <span class="n">columns</span><span class="o">=</span><span class="s">'weeks_since_first_order'</span><span class="p">,</span>
                                       <span class="n">values</span><span class="o">=</span><span class="s">'customer_id'</span><span class="p">)</span>
<span class="n">cohort_count</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/retention/cohort-4.png" alt="cohort-4" width="600" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">retention</span> <span class="o">=</span> <span class="n">cohort_count</span><span class="p">.</span><span class="nf">divide</span><span class="p">(</span><span class="n">cohort_count</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/retention/cohort-5.png" alt="cohort-5" width="600" /></p>

<p>Plotting cohort using seaborn</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="s">'Customer retention based on first order week'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">retention</span><span class="p">,</span>
            <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">fmt</span> <span class="o">=</span> <span class="s">'.0%'</span><span class="p">,</span>
            <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">vmax</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s">'YlGnBu'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="s">'retention-heatmap.png'</span><span class="p">,</span> <span class="n">transparent</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/retention/retention-heatmap.png" alt="heatmap" width="900" /></p>

<h3 id="using-cohort-heatmap">Using cohort heatmap</h3>

<p>Each row of the chart corresponds to a temporal cohort. The first column is always equal to 100% because, and subsequnt columns shows that percentage of that cohort remaning after a given period of time.</p>

<ul>
  <li>Horizontal features identify a cohort-specific trait. For example, if you were to run an ad campaign in a given week, you might see a horizontal feature emerge showing improved or dimished retentino particular to that cohort. In the heatmap, week 24 cohort has significantly lower retention than the neighboring weeks. By week 6, less than 10% of the cohort remained.</li>
  <li>Diagonal features are usually the results of product or performance changes. The first few weeks from week 18 to 22 tends to have greater retention than the later weeks. This might indicate that product quality might have been deteriorating.</li>
  <li>Vertical features are commonly seens in subcription services. For example, a dollar chart might show a significant feature every 12 months when portions of cohorts renew their memership.</li>
</ul>

<p>Since total retention is the weighted average of cohort retentions, it is important to track cohorts that are much greater than others.</p>

<h3 id="end">End</h3>]]></content><author><name>Vo Duy Do</name></author><category term="retention" /><category term="visualization" /><category term="analysis" /><summary type="html"><![CDATA[Using pandas to create a retention chart segmented by cohorts. Identifying trends across rows, columns and diagonal features.]]></summary></entry><entry><title type="html">Creating a pokemon guesser</title><link href="https://dobeok.github.io//jekyll-theme-yat/2022/06/01/pokermon-guesser.html" rel="alternate" type="text/html" title="Creating a pokemon guesser" /><published>2022-06-01T04:00:00+00:00</published><updated>2022-06-01T04:00:00+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2022/06/01/pokermon-guesser</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2022/06/01/pokermon-guesser.html"><![CDATA[<h3 id="introduction">Introduction</h3>

<p>“Who’s that pokemon?” is a well known trivia game where people are shown silhouette of a pokemon and then try to guess its name. In this post, I will recreate the images. To do so, I  start off with a colored image of a pokemon, and then extract its sihoulette using contour detection. In addition to the base game, I will also add some flavors. For example: adding hints by showing a pixelated image, or revealing part of the original image.</p>

<p><img src="/assets/images/posts/pokemon-guesser/pokemon-banner.jpg" alt="demo" /></p>

<h3 id="getting-the-base-images">Getting the base images</h3>

<p>It’s best to get all base images from the same source so that the art style is consistent. <a href="https://pokemondb.net/">pokemondb.net</a> has a nice and complete list of images from all generations. In the code to download images, I have added some random delay to slow down the requests.</p>

<pre><code class="language-python3">import requests
import random
import time
import pandas as pd

try:
    plist = pd.read_csv('./resources/pokemon_list.csv', usecols=['pokemon'])['pokemon'].tolist()
except:
    # fallback in case file's not available
    plist = ['carvanha', 'tangrowth', 'simisear', 'scyther', 'tentacruel', 'clawitzer',
        'trevenant', 'gardevoir', 'venomoth', 'perrserker']

if __name__ == '__main__':
    
    for idx, pokemon_name in enumerate(plist):
        image_url = f'https://img.pokemondb.net/artwork/vector/large/{pokemon_name}.png'
        

        img_data = requests.get(image_url).content
        with open(f'./resources/img_pokemon_png/{pokemon_name}.png', 'wb') as handler:
            handler.write(img_data)

        time.sleep(random.random() * 5)

</code></pre>
<!-- <script src="https://gist.github.com/dobeok/17e5b302e067e92dbf93c87a78094003.js"></script> -->

<h3 id="processing-the-image">Processing the image</h3>

<p>The steps to process the images are:</p>

<ol>
  <li>Convert to grayscale (and optionally, image thresholding)</li>
  <li>Choose a contour retrieval method</li>
  <li>Adding background</li>
</ol>

<h4 id="read-image-convert-to-grayscale-and-thresholding">Read image, convert to grayscale, and thresholding</h4>

<p>While processing images, I like to create multiple subplots to keep reference of the original image and keep track of the transformations.</p>

<pre><code class="language-python3">import cv2
import matplotlib.pyplot as plt


file_name = 'resources/img_pokemon_jpg/amoonguss.jpg'

# here I keep both the colored and grayscale images to better visualise the output
# note that cv2 use BGR color space,
# so we need to use cv2.cvtColor method to convert back to RGB
# when plotting with `matplotlib` to show true colors

img_bgr = cv2.imread(img, cv2)
img_gray = cv2.imread(file_name, cv2.IMREAD_GRAYSCALE)

</code></pre>

<h4 id="finding-contours">Finding contours</h4>

<pre><code class="language-python3">fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(12, 6), sharey=True)

axes[0].set_title('Original Image', fontsize=14)
axes[1].set_title('Grayscaled Image', fontsize=14)
axes[2].set_title('All Contours', fontsize=14)
axes[3].set_title('External Contours', fontsize=14)

# orignal image
axes[0].imshow(img_rgb)

# greyscaled image
ret, thresh = cv2.threshold(img_gray, 100, 255, 0)
axes[1].imshow(cv2.cvtColor(img_gray, cv2.COLOR_BGR2RGB))
axes[0].imshow(thresh)
</code></pre>

<p>From the documentation, cv2.findContours has 4 different retrieval modes:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">RETR_EXTERNAL</code>: retrieves only the extreme outer contours <em>(what we want)</em></li>
  <li><code class="language-plaintext highlighter-rouge">RETR_LIST</code>: retrieves all of the contours without establishing any hierarchical relationships.</li>
  <li><code class="language-plaintext highlighter-rouge">RETR_CCOMP</code>: retrieves all of the contours and organizes them into a two-level hierarchy. At the top level, there are external boundaries of the components. At the second level, there are boundaries of the holes. If there is another contour inside a hole of a connected component, it is still put at the top level.</li>
  <li><code class="language-plaintext highlighter-rouge">RETR_TREE</code>:retrieves all of the contours and reconstructs a full hierarchy of nested contours.</li>
</ul>

<p>We only need the outer contour, so I will run with <code class="language-plaintext highlighter-rouge">RETR_EXTERNAL</code> flag. However, to illustrate the different possibilities, I will plot both the External Contours and all contours.</p>

<pre><code class="language-python3"># all contours
contours, _ = cv2.findContours(img_gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
canvas = np.zeros_like(img_gray)
cv2.drawContours(canvas, contours, -1, (255, 255, 0), 3)
axes[2].imshow(canvas)



# external contours
contours, _ = cv2.findContours(img_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
canvas = np.zeros_like(img_gray)
cv2.drawContours(canvas, contours, -1, (255, 255, 0), 3)
axes[3].imshow(canvas)

</code></pre>

<p><img src="/assets/images/posts/pokemon-guesser/contours-amoonguss.png" alt="img" /></p>

<h4 id="merging-contour-with-the-background">Merging contour with the background</h4>

<p>The remaining task is to add a background to the sihlouette. A simple solution is just to align the siloulette’s centroid with a chosen point on the background. Since the background image can be recycled, I can hardcode the coordiate and here I chose the point at 600, 550</p>

<p><img src="/assets/images/posts/pokemon-guesser/template.jpg" alt="background" /></p>

<pre><code class="language-python3">
CENTER_COORDS = 600, 550
FILL_COLOR =  (142, 100, 46)

def shift_center(contours, center_coords=CENTER_COORDS):
    """
    align the image with the template
    """

    # find centroid of the sihoulette
    M = cv2.moments(contours[0])
    
    cX = int(M["m10"] / M["m00"])
    cY = int(M["m01"] / M["m00"])
    
    # calculate distance to shift
    delta_X = center_coords[0] - cX
    delta_Y = center_coords[1] - cY

    # contours are returned as tuple (numpy_array, )
    coords_array = contours[0]

    coords_array[:, :, 0] = coords_array[:, :, 0] + delta_Y
    coords_array[:, :, 1] = coords_array[:, :, 1] + delta_X

    return contours
    

# read template image
template_path = './resources/template.jpg'

contours = shift_center(contours)


base = cv2.imread(template_path)
cv2.drawContours(base, contours, -1, thickness=2, lineType=cv2.LINE_AA, color=(0, 0, 0))
plt.imshow(base)

# color the contour to create silhouette effects
</code></pre>

<h3 id="final-result">Final result</h3>

<p>Putting everything together, we achieve what looks just like the original game! Perhaps you might want to play around with positioning, or trying out different colors depending on your creativity.</p>

<p><img src="/assets/images/posts/pokemon-guesser/final-amoonguss.png" alt="amoonguss" /></p>

<h4 id="more-to-come">More to come</h4>

<p>In addition to the basic silhouette effects, I’ve also tinkered with pixelating and re-coloring the images to add some variations. I will make a follow up post sharing the process.</p>

<p><img src="/assets/images/posts/pokemon-guesser/pixelate demo.jpg" style="max-width: 600px;" /></p>

<h3 id="end">End</h3>

<!-- https://twitter.com/Marco_Piani/status/1567880008697352195 -->]]></content><author><name>Vo Duy Do</name></author><category term="image-processing" /><category term="opencv" /><category term="numpy" /><summary type="html"><![CDATA[Using openCV to extract image contours and process image akin to guess the pokemon games]]></summary></entry><entry><title type="html">Building a DCA simulation apps with Streamlit</title><link href="https://dobeok.github.io//jekyll-theme-yat/2022/04/01/DCA-apps.html" rel="alternate" type="text/html" title="Building a DCA simulation apps with Streamlit" /><published>2022-04-01T05:00:00+00:00</published><updated>2022-04-01T05:00:00+00:00</updated><id>https://dobeok.github.io//jekyll-theme-yat/2022/04/01/DCA-apps</id><content type="html" xml:base="https://dobeok.github.io//jekyll-theme-yat/2022/04/01/DCA-apps.html"><![CDATA[<p><a href="https://dobeok-crypto-dca-app-app-4uppgz.streamlitapp.com/">Link to the streamlit apps</a></p>

<p><a href="https://dobeok-crypto-dca-app-app-4uppgz.streamlitapp.com/"><img src="/assets/images/posts/dca-crypto/app-preview.jpg" alt="st-app" /></a></p>

<h2 id="what-is-dca">What is DCA?</h2>
<p>DCA stands for “Dollar Cost Averaging” and it refers to a strategy of investing a fixed amount of money into an asset at regular intervals over a long period of time, rather than making a lump-sum investment all at once.</p>

<table>
  <thead>
    <tr>
      <th>Benefits</th>
      <th>Drawbacks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>* **Reduced risk of buying at a market high:** By investing a fixed amount at regular intervals, you reduce the risk of investing a large amount of money at the wrong time, such as when the market is at a high point.</td>
      <td>* **Missed opportunities:** If the market is rising, you may miss out on the potential for higher returns by not investing a larger amount when the market is high.</td>
    </tr>
    <tr>
      <td>* **Averaging in:** Over time, DCA helps to average out the cost of an investment, potentially reducing the average cost per unit of the asset.</td>
      <td>* **No guarantee of higher returns:** Just because DCA reduces the risk of buying at a market high, it does not guarantee higher returns.</td>
    </tr>
    <tr>
      <td>* **Mental discipline:** DCA can also help to encourage a disciplined investment approach, as it requires setting aside a fixed amount of money on a regular basis and sticking to the plan, even during market fluctuations</td>
      <td>* **Timing still matters**: While DCA can help to average out the cost of an investment, timing still matters. If the market declines significantly over the long-term, the overall return on investment will likely be lower.</td>
    </tr>
  </tbody>
</table>

<p>DCA can be a good strategy for some investors, especially those who are risk-averse and want to reduce the impact of market fluctuations on their investments. However, it is not a guaranteed strategy and like any investment, it involves risk. It is important to consider your personal financial situation and investment goals before choosing an investment strategy.</p>]]></content><author><name>Vo Duy Do</name></author><category term="visualization" /><category term="streamlit" /><summary type="html"><![CDATA[Creating a Dollar Cost Average (DCA) calculator using streamlit]]></summary></entry></feed>